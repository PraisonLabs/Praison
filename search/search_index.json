{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Praison AI","text":"<p>Praison AI, leveraging both AutoGen and CrewAI or any other agent framework, represents a low-code, centralised framework designed to simplify the creation and orchestration of multi-agent systems for various LLM applications, emphasizing ease of use, customization, and human-agent interaction.</p>"},{"location":"#prerequisite","title":"Prerequisite:","text":""},{"location":"#export-api-key","title":"Export API KEY","text":"<pre><code>export OPENAI_API_KEY=\"Enter your API key\"\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install praisonai\n</code></pre>"},{"location":"#automatically-create-agents-to-perform-a-task","title":"Automatically Create Agents to Perform a Task","text":"<pre><code>praisonai --init create a movie script about dog in moon\n</code></pre>"},{"location":"#run","title":"Run","text":"<pre><code>praisonai\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#praisonai.auto.AutoGenerator","title":"<code>AutoGenerator</code>","text":"Source code in <code>praisonai/auto.py</code> <pre><code>class AutoGenerator:\n    def __init__(self, topic=\"Movie Story writing about AI\", agent_file=\"test.yaml\", framework=\"crewai\", config_list: Optional[List[Dict]] = None):\n        \"\"\"\n        Initialize the AutoGenerator class with the specified topic, agent file, and framework.\n        Note: autogen framework is different from this AutoGenerator class.\n\n        Args:\n            topic (str, optional): The topic for the generated team structure. Defaults to \"Movie Story writing about AI\".\n            agent_file (str, optional): The name of the YAML file to save the generated team structure. Defaults to \"test.yaml\".\n            framework (str, optional): The framework for the generated team structure. Defaults to \"crewai\".\n            config_list (Optional[List[Dict]], optional): A list containing the configuration details for the OpenAI API. \n                                                          If None, it defaults to using environment variables or hardcoded values.\n        Attributes:\n            config_list (list): A list containing the configuration details for the OpenAI API.\n            topic (str): The specified topic for the generated team structure.\n            agent_file (str): The specified name of the YAML file to save the generated team structure.\n            framework (str): The specified framework for the generated team structure.\n            client (instructor.Client): An instance of the instructor.Client class initialized with the specified OpenAI API configuration.\n        \"\"\"\n        self.config_list = config_list or [\n            {\n                'model': os.environ.get(\"OPENAI_MODEL_NAME\", \"gpt-4o\"),\n                'base_url': os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n                'api_key': os.environ.get(\"OPENAI_API_KEY\")\n            }\n        ]\n        self.topic = topic\n        self.agent_file = agent_file\n        self.framework = framework or \"crewai\"\n        self.client = instructor.patch(\n            OpenAI(\n                base_url=self.config_list[0]['base_url'],\n                api_key=os.getenv(\"OPENAI_API_KEY\"),\n            ),\n            mode=instructor.Mode.JSON,\n        )\n\n    def generate(self):\n        \"\"\"\n        Generates a team structure for the specified topic.\n\n        Args:\n            None\n\n        Returns:\n            str: The full path of the YAML file containing the generated team structure.\n\n        Raises:\n            Exception: If the generation process fails.\n\n        Usage:\n            generator = AutoGenerator(framework=\"crewai\", topic=\"Create a movie script about Cat in Mars\")\n            path = generator.generate()\n            print(path)\n        \"\"\"\n        response = self.client.chat.completions.create(\n            model=self.config_list[0]['model'],\n            response_model=TeamStructure,\n            max_retries=10,\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output complex team structures.\"},\n                {\"role\": \"user\", \"content\": self.get_user_content()}\n            ]\n        )\n        json_data = json.loads(response.model_dump_json())\n        self.convert_and_save(json_data)\n        full_path = os.path.abspath(self.agent_file)\n        return full_path\n\n    def convert_and_save(self, json_data):\n        \"\"\"Converts the provided JSON data into the desired YAML format and saves it to a file.\n\n        Args:\n            json_data (dict): The JSON data representing the team structure.\n            topic (str, optional): The topic to be inserted into the YAML. Defaults to \"Artificial Intelligence\".\n            agent_file (str, optional): The name of the YAML file to save. Defaults to \"test.yaml\".\n        \"\"\"\n\n        yaml_data = {\n            \"framework\": self.framework,\n            \"topic\": self.topic,\n            \"roles\": {},\n            \"dependencies\": []\n        }\n\n        for role_id, role_details in json_data['roles'].items():\n            yaml_data['roles'][role_id] = {\n                \"backstory\": \"\" + role_details['backstory'],\n                \"goal\": role_details['goal'],\n                \"role\": role_details['role'],\n                \"tasks\": {},\n                # \"tools\": role_details.get('tools', []),\n                \"tools\": ['']\n            }\n\n            for task_id, task_details in role_details['tasks'].items():\n                yaml_data['roles'][role_id]['tasks'][task_id] = {\n                    \"description\": \"\" + task_details['description'],\n                    \"expected_output\": \"\" + task_details['expected_output']\n                }\n\n        # Save to YAML file, maintaining the order\n        with open(self.agent_file, 'w') as f:\n            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)\n\n    def get_user_content(self):\n        \"\"\"\n        Generates a prompt for the OpenAI API to generate a team structure.\n\n        Args:\n            None\n\n        Returns:\n            str: The prompt for the OpenAI API.\n\n        Usage:\n            generator = AutoGenerator(framework=\"crewai\", topic=\"Create a movie script about Cat in Mars\")\n            prompt = generator.get_user_content()\n            print(prompt)\n        \"\"\"\n        user_content = \"\"\"Generate a team structure for  \\\"\"\"\" + self.topic + \"\"\"\\\" task. \nNo Input data will be provided to the team.\nThe team will work in sequence. First role will pass the output to the next role, and so on.\nThe last role will generate the final output.\nThink step by step.\nWith maximum 3 roles, each with 1 task. Include role goals, backstories, task descriptions, and expected outputs.\nList of Available Tools: CodeDocsSearchTool, CSVSearchTool, DirectorySearchTool, DOCXSearchTool, DirectoryReadTool, FileReadTool, TXTSearchTool, JSONSearchTool, MDXSearchTool, PDFSearchTool, RagTool, ScrapeElementFromWebsiteTool, ScrapeWebsiteTool, WebsiteSearchTool, XMLSearchTool, YoutubeChannelSearchTool, YoutubeVideoSearchTool.\nOnly use Available Tools. Do Not use any other tools. \nExample Below: \nUse below example to understand the structure of the output. \nThe final role you create should satisfy the provided task: \"\"\" + self.topic + \"\"\".\n{\n\"roles\": {\n\"narrative_designer\": {\n\"role\": \"Narrative Designer\",\n\"goal\": \"Create AI storylines\",\n\"backstory\": \"Skilled in narrative development for AI, with a focus on story resonance.\",\n\"tools\": [\"ScrapeWebsiteTool\"],\n\"tasks\": {\n\"story_concept_development\": {\n\"description\": \"Craft a unique AI story concept with depth and engagement using concept from this page the content https://www.asthebirdfliesblog.com/posts/how-to-write-book-story-development .\",\n\"expected_output\": \"Document with narrative arcs, character bios, and settings.\"\n}\n}\n},\n\"scriptwriter\": {\n\"role\": \"Scriptwriter\",\n\"goal\": \"Write scripts from AI concepts\",\n\"backstory\": \"Expert in dialogue and script structure, translating concepts into scripts.\",\n\"tasks\": {\n\"scriptwriting_task\": {\n\"description\": \"Turn narrative concepts into scripts, including dialogue and scenes.\",\n\"expected_output\": \"Production-ready script with dialogue and scene details.\"\n}\n}\n}\n}\n}\n        \"\"\"\n        return user_content\n</code></pre>"},{"location":"api/#praisonai.auto.AutoGenerator.__init__","title":"<code>__init__(topic='Movie Story writing about AI', agent_file='test.yaml', framework='crewai', config_list=None)</code>","text":"<p>Initialize the AutoGenerator class with the specified topic, agent file, and framework. Note: autogen framework is different from this AutoGenerator class.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>The topic for the generated team structure. Defaults to \"Movie Story writing about AI\".</p> <code>'Movie Story writing about AI'</code> <code>agent_file</code> <code>str</code> <p>The name of the YAML file to save the generated team structure. Defaults to \"test.yaml\".</p> <code>'test.yaml'</code> <code>framework</code> <code>str</code> <p>The framework for the generated team structure. Defaults to \"crewai\".</p> <code>'crewai'</code> <code>config_list</code> <code>Optional[List[Dict]]</code> <p>A list containing the configuration details for the OpenAI API.                                            If None, it defaults to using environment variables or hardcoded values.</p> <code>None</code> <p>Attributes:     config_list (list): A list containing the configuration details for the OpenAI API.     topic (str): The specified topic for the generated team structure.     agent_file (str): The specified name of the YAML file to save the generated team structure.     framework (str): The specified framework for the generated team structure.     client (instructor.Client): An instance of the instructor.Client class initialized with the specified OpenAI API configuration.</p> Source code in <code>praisonai/auto.py</code> <pre><code>def __init__(self, topic=\"Movie Story writing about AI\", agent_file=\"test.yaml\", framework=\"crewai\", config_list: Optional[List[Dict]] = None):\n    \"\"\"\n    Initialize the AutoGenerator class with the specified topic, agent file, and framework.\n    Note: autogen framework is different from this AutoGenerator class.\n\n    Args:\n        topic (str, optional): The topic for the generated team structure. Defaults to \"Movie Story writing about AI\".\n        agent_file (str, optional): The name of the YAML file to save the generated team structure. Defaults to \"test.yaml\".\n        framework (str, optional): The framework for the generated team structure. Defaults to \"crewai\".\n        config_list (Optional[List[Dict]], optional): A list containing the configuration details for the OpenAI API. \n                                                      If None, it defaults to using environment variables or hardcoded values.\n    Attributes:\n        config_list (list): A list containing the configuration details for the OpenAI API.\n        topic (str): The specified topic for the generated team structure.\n        agent_file (str): The specified name of the YAML file to save the generated team structure.\n        framework (str): The specified framework for the generated team structure.\n        client (instructor.Client): An instance of the instructor.Client class initialized with the specified OpenAI API configuration.\n    \"\"\"\n    self.config_list = config_list or [\n        {\n            'model': os.environ.get(\"OPENAI_MODEL_NAME\", \"gpt-4o\"),\n            'base_url': os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n            'api_key': os.environ.get(\"OPENAI_API_KEY\")\n        }\n    ]\n    self.topic = topic\n    self.agent_file = agent_file\n    self.framework = framework or \"crewai\"\n    self.client = instructor.patch(\n        OpenAI(\n            base_url=self.config_list[0]['base_url'],\n            api_key=os.getenv(\"OPENAI_API_KEY\"),\n        ),\n        mode=instructor.Mode.JSON,\n    )\n</code></pre>"},{"location":"api/#praisonai.auto.AutoGenerator.convert_and_save","title":"<code>convert_and_save(json_data)</code>","text":"<p>Converts the provided JSON data into the desired YAML format and saves it to a file.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>dict</code> <p>The JSON data representing the team structure.</p> required <code>topic</code> <code>str</code> <p>The topic to be inserted into the YAML. Defaults to \"Artificial Intelligence\".</p> required <code>agent_file</code> <code>str</code> <p>The name of the YAML file to save. Defaults to \"test.yaml\".</p> required Source code in <code>praisonai/auto.py</code> <pre><code>def convert_and_save(self, json_data):\n    \"\"\"Converts the provided JSON data into the desired YAML format and saves it to a file.\n\n    Args:\n        json_data (dict): The JSON data representing the team structure.\n        topic (str, optional): The topic to be inserted into the YAML. Defaults to \"Artificial Intelligence\".\n        agent_file (str, optional): The name of the YAML file to save. Defaults to \"test.yaml\".\n    \"\"\"\n\n    yaml_data = {\n        \"framework\": self.framework,\n        \"topic\": self.topic,\n        \"roles\": {},\n        \"dependencies\": []\n    }\n\n    for role_id, role_details in json_data['roles'].items():\n        yaml_data['roles'][role_id] = {\n            \"backstory\": \"\" + role_details['backstory'],\n            \"goal\": role_details['goal'],\n            \"role\": role_details['role'],\n            \"tasks\": {},\n            # \"tools\": role_details.get('tools', []),\n            \"tools\": ['']\n        }\n\n        for task_id, task_details in role_details['tasks'].items():\n            yaml_data['roles'][role_id]['tasks'][task_id] = {\n                \"description\": \"\" + task_details['description'],\n                \"expected_output\": \"\" + task_details['expected_output']\n            }\n\n    # Save to YAML file, maintaining the order\n    with open(self.agent_file, 'w') as f:\n        yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)\n</code></pre>"},{"location":"api/#praisonai.auto.AutoGenerator.generate","title":"<code>generate()</code>","text":"<p>Generates a team structure for the specified topic.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The full path of the YAML file containing the generated team structure.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the generation process fails.</p> Usage <p>generator = AutoGenerator(framework=\"crewai\", topic=\"Create a movie script about Cat in Mars\") path = generator.generate() print(path)</p> Source code in <code>praisonai/auto.py</code> <pre><code>def generate(self):\n    \"\"\"\n    Generates a team structure for the specified topic.\n\n    Args:\n        None\n\n    Returns:\n        str: The full path of the YAML file containing the generated team structure.\n\n    Raises:\n        Exception: If the generation process fails.\n\n    Usage:\n        generator = AutoGenerator(framework=\"crewai\", topic=\"Create a movie script about Cat in Mars\")\n        path = generator.generate()\n        print(path)\n    \"\"\"\n    response = self.client.chat.completions.create(\n        model=self.config_list[0]['model'],\n        response_model=TeamStructure,\n        max_retries=10,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output complex team structures.\"},\n            {\"role\": \"user\", \"content\": self.get_user_content()}\n        ]\n    )\n    json_data = json.loads(response.model_dump_json())\n    self.convert_and_save(json_data)\n    full_path = os.path.abspath(self.agent_file)\n    return full_path\n</code></pre>"},{"location":"api/#praisonai.auto.AutoGenerator.get_user_content","title":"<code>get_user_content()</code>","text":"<p>Generates a prompt for the OpenAI API to generate a team structure.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The prompt for the OpenAI API.</p> Usage <p>generator = AutoGenerator(framework=\"crewai\", topic=\"Create a movie script about Cat in Mars\") prompt = generator.get_user_content() print(prompt)</p> Source code in <code>praisonai/auto.py</code> <pre><code>    def get_user_content(self):\n        \"\"\"\n        Generates a prompt for the OpenAI API to generate a team structure.\n\n        Args:\n            None\n\n        Returns:\n            str: The prompt for the OpenAI API.\n\n        Usage:\n            generator = AutoGenerator(framework=\"crewai\", topic=\"Create a movie script about Cat in Mars\")\n            prompt = generator.get_user_content()\n            print(prompt)\n        \"\"\"\n        user_content = \"\"\"Generate a team structure for  \\\"\"\"\" + self.topic + \"\"\"\\\" task. \nNo Input data will be provided to the team.\nThe team will work in sequence. First role will pass the output to the next role, and so on.\nThe last role will generate the final output.\nThink step by step.\nWith maximum 3 roles, each with 1 task. Include role goals, backstories, task descriptions, and expected outputs.\nList of Available Tools: CodeDocsSearchTool, CSVSearchTool, DirectorySearchTool, DOCXSearchTool, DirectoryReadTool, FileReadTool, TXTSearchTool, JSONSearchTool, MDXSearchTool, PDFSearchTool, RagTool, ScrapeElementFromWebsiteTool, ScrapeWebsiteTool, WebsiteSearchTool, XMLSearchTool, YoutubeChannelSearchTool, YoutubeVideoSearchTool.\nOnly use Available Tools. Do Not use any other tools. \nExample Below: \nUse below example to understand the structure of the output. \nThe final role you create should satisfy the provided task: \"\"\" + self.topic + \"\"\".\n{\n\"roles\": {\n\"narrative_designer\": {\n\"role\": \"Narrative Designer\",\n\"goal\": \"Create AI storylines\",\n\"backstory\": \"Skilled in narrative development for AI, with a focus on story resonance.\",\n\"tools\": [\"ScrapeWebsiteTool\"],\n\"tasks\": {\n\"story_concept_development\": {\n\"description\": \"Craft a unique AI story concept with depth and engagement using concept from this page the content https://www.asthebirdfliesblog.com/posts/how-to-write-book-story-development .\",\n\"expected_output\": \"Document with narrative arcs, character bios, and settings.\"\n}\n}\n},\n\"scriptwriter\": {\n\"role\": \"Scriptwriter\",\n\"goal\": \"Write scripts from AI concepts\",\n\"backstory\": \"Expert in dialogue and script structure, translating concepts into scripts.\",\n\"tasks\": {\n\"scriptwriting_task\": {\n\"description\": \"Turn narrative concepts into scripts, including dialogue and scenes.\",\n\"expected_output\": \"Production-ready script with dialogue and scene details.\"\n}\n}\n}\n}\n}\n        \"\"\"\n        return user_content\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator","title":"<code>AgentsGenerator</code>","text":"Source code in <code>praisonai/agents_generator.py</code> <pre><code>class AgentsGenerator:\n    def __init__(self, agent_file, framework, config_list, log_level=None, agent_callback=None, task_callback=None, agent_yaml=None):\n        \"\"\"\n        Initialize the AgentsGenerator object.\n\n        Parameters:\n            agent_file (str): The path to the agent file.\n            framework (str): The framework to be used for the agents.\n            config_list (list): A list of configurations for the agents.\n            log_level (int, optional): The logging level to use. Defaults to logging.INFO.\n            agent_callback (callable, optional): A callback function to be executed after each agent step.\n            task_callback (callable, optional): A callback function to be executed after each tool run.\n            agent_yaml (str, optional): The content of the YAML file. Defaults to None.\n\n        Attributes:\n            agent_file (str): The path to the agent file.\n            framework (str): The framework to be used for the agents.\n            config_list (list): A list of configurations for the agents.\n            log_level (int): The logging level to use.\n            agent_callback (callable, optional): A callback function to be executed after each agent step.\n            task_callback (callable, optional): A callback function to be executed after each tool run.\n        \"\"\"\n        self.agent_file = agent_file\n        self.framework = framework\n        self.config_list = config_list\n        self.log_level = log_level\n        self.agent_callback = agent_callback\n        self.task_callback = task_callback\n        self.agent_yaml = agent_yaml\n        self.log_level = log_level or logging.getLogger().getEffectiveLevel()\n        if self.log_level == logging.NOTSET:\n            self.log_level = os.environ.get('LOGLEVEL', 'INFO').upper()\n\n        logging.basicConfig(level=self.log_level, format='%(asctime)s - %(levelname)s - %(message)s')\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(self.log_level)\n\n    def is_function_or_decorated(self, obj):\n        \"\"\"\n        Checks if the given object is a function or has a __call__ method.\n\n        Parameters:\n            obj (object): The object to be checked.\n\n        Returns:\n            bool: True if the object is a function or has a __call__ method, False otherwise.\n        \"\"\"\n        return inspect.isfunction(obj) or hasattr(obj, '__call__')\n\n    def load_tools_from_module(self, module_path):\n        \"\"\"\n        Loads tools from a specified module path.\n\n        Parameters:\n            module_path (str): The path to the module containing the tools.\n\n        Returns:\n            dict: A dictionary containing the names of the tools as keys and the corresponding functions or objects as values.\n\n        Raises:\n            FileNotFoundError: If the specified module path does not exist.\n        \"\"\"\n        spec = importlib.util.spec_from_file_location(\"tools_module\", module_path)\n        module = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(module)\n        return {name: obj for name, obj in inspect.getmembers(module, self.is_function_or_decorated)}\n\n    def load_tools_from_module_class(self, module_path):\n        \"\"\"\n        Loads tools from a specified module path containing classes that inherit from BaseTool or are part of langchain_community.tools package.\n\n        Parameters:\n            module_path (str): The path to the module containing the tools.\n\n        Returns:\n            dict: A dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.\n\n        Raises:\n            FileNotFoundError: If the specified module path does not exist.\n        \"\"\"\n        spec = importlib.util.spec_from_file_location(\"tools_module\", module_path)\n        module = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(module)\n        return {name: obj() for name, obj in inspect.getmembers(module, lambda x: inspect.isclass(x) and (x.__module__.startswith('langchain_community.tools') or issubclass(x, BaseTool)) and x is not BaseTool)}\n\n    def load_tools_from_package(self, package_path):\n        \"\"\"\n        Loads tools from a specified package path containing modules with functions or classes.\n\n        Parameters:\n            package_path (str): The path to the package containing the tools.\n\n        Returns:\n            dict: A dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.\n\n        Raises:\n            FileNotFoundError: If the specified package path does not exist.\n\n        This function iterates through all the .py files in the specified package path, excluding those that start with \"__\". For each file, it imports the corresponding module and checks if it contains any functions or classes that can be loaded as tools. The function then returns a dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.\n        \"\"\"\n        tools_dict = {}\n        for module_file in os.listdir(package_path):\n            if module_file.endswith('.py') and not module_file.startswith('__'):\n                module_name = f\"{package_path.name}.{module_file[:-3]}\"  # Remove .py for import\n                module = importlib.import_module(module_name)\n                for name, obj in inspect.getmembers(module, self.is_function_or_decorated):\n                    tools_dict[name] = obj\n        return tools_dict\n\n    def generate_crew_and_kickoff(self):\n        \"\"\"\n        Generates a crew of agents and initiates tasks based on the provided configuration.\n\n        Parameters:\n            agent_file (str): The path to the agent file.\n            framework (str): The framework to be used for the agents.\n            config_list (list): A list of configurations for the agents.\n\n        Returns:\n            str: The output of the tasks performed by the crew of agents.\n\n        Raises:\n            FileNotFoundError: If the specified agent file does not exist.\n\n        This function first loads the agent configuration from the specified file. It then initializes the tools required for the agents based on the specified framework. If the specified framework is \"autogen\", it loads the LLM configuration dynamically and creates an AssistantAgent for each role in the configuration. It then adds tools to the agents if specified in the configuration. Finally, it prepares tasks for the agents based on the configuration and initiates the tasks using the crew of agents. If the specified framework is not \"autogen\", it creates a crew of agents and initiates tasks based on the configuration.\n        \"\"\"\n        if self.agent_yaml:\n            config = yaml.safe_load(self.agent_yaml)\n        else:\n            if self.agent_file == '/app/api:app' or self.agent_file == 'api:app':\n                self.agent_file = 'agents.yaml'\n            try:\n                with open(self.agent_file, 'r') as f:\n                    config = yaml.safe_load(f)\n            except FileNotFoundError:\n                print(f\"File not found: {self.agent_file}\")\n                return\n\n        topic = config['topic']\n        tools_dict = {\n            'CodeDocsSearchTool': CodeDocsSearchTool(),\n            'CSVSearchTool': CSVSearchTool(),\n            'DirectorySearchTool': DirectorySearchTool(),\n            'DOCXSearchTool': DOCXSearchTool(),\n            'DirectoryReadTool': DirectoryReadTool(),\n            'FileReadTool': FileReadTool(),\n            # 'GithubSearchTool': GithubSearchTool(),\n            # 'SeperDevTool': SeperDevTool(),\n            'TXTSearchTool': TXTSearchTool(),\n            'JSONSearchTool': JSONSearchTool(),\n            'MDXSearchTool': MDXSearchTool(),\n            'PDFSearchTool': PDFSearchTool(),\n            # 'PGSearchTool': PGSearchTool(),\n            'RagTool': RagTool(),\n            'ScrapeElementFromWebsiteTool': ScrapeElementFromWebsiteTool(),\n            'ScrapeWebsiteTool': ScrapeWebsiteTool(),\n            'WebsiteSearchTool': WebsiteSearchTool(),\n            'XMLSearchTool': XMLSearchTool(),\n            'YoutubeChannelSearchTool': YoutubeChannelSearchTool(),\n            'YoutubeVideoSearchTool': YoutubeVideoSearchTool(),\n        }\n        root_directory = os.getcwd()\n        tools_py_path = os.path.join(root_directory, 'tools.py')\n        tools_dir_path = Path(root_directory) / 'tools'\n\n        if os.path.isfile(tools_py_path):\n            tools_dict.update(self.load_tools_from_module_class(tools_py_path))\n            self.logger.debug(\"tools.py exists in the root directory. Loading tools.py and skipping tools folder.\")\n        elif tools_dir_path.is_dir():\n            tools_dict.update(self.load_tools_from_module_class(tools_dir_path))\n            self.logger.debug(\"tools folder exists in the root directory\")\n\n        framework = self.framework or config.get('framework')\n\n        agents = {}\n        tasks = []\n        if framework == \"autogen\":\n            # Load the LLM configuration dynamically\n            # print(self.config_list)\n            llm_config = {\"config_list\": self.config_list}\n\n            if agentops_exists:\n                agentops.init(os.environ.get(\"AGENTOPS_API_KEY\"), tags=[\"autogen\"])\n            # Assuming the user proxy agent is set up as per your requirements\n            user_proxy = autogen.UserProxyAgent(\n                name=\"User\",\n                human_input_mode=\"NEVER\",\n                is_termination_msg=lambda x: (x.get(\"content\") or \"\").rstrip().rstrip(\".\").lower().endswith(\"terminate\") or \"TERMINATE\" in (x.get(\"content\") or \"\"),\n                code_execution_config={\n                    \"work_dir\": \"coding\",\n                    \"use_docker\": False,\n                },\n                # additional setup for the user proxy agent\n            )\n\n            for role, details in config['roles'].items():\n                agent_name = details['role'].format(topic=topic).replace(\"{topic}\", topic)\n                agent_goal = details['goal'].format(topic=topic)\n                # Creating an AssistantAgent for each role dynamically\n                agents[role] = autogen.AssistantAgent(\n                    name=agent_name,\n                    llm_config=llm_config,\n                    system_message=details['backstory'].format(topic=topic)+\". Must Reply \\\"TERMINATE\\\" in the end when everything is done.\",\n                )\n                for tool in details.get('tools', []):\n                    if tool in tools_dict:\n                        try:\n                            tool_class = globals()[f'autogen_{type(tools_dict[tool]).__name__}']\n                            print(f\"Found {tool_class.__name__} for {tool}\")\n                        except KeyError:\n                            print(f\"Warning: autogen_{type(tools_dict[tool]).__name__} function not found. Skipping this tool.\")\n                            continue\n                        tool_class(agents[role], user_proxy)\n\n                # Preparing tasks for initiate_chats\n                for task_name, task_details in details.get('tasks', {}).items():\n                    description_filled = task_details['description'].format(topic=topic)\n                    expected_output_filled = task_details['expected_output'].format(topic=topic)\n\n                    chat_task = {\n                        \"recipient\": agents[role],\n                        \"message\": description_filled,\n                        \"summary_method\": \"last_msg\", \n                        # Additional fields like carryover can be added based on dependencies\n                    }\n                    tasks.append(chat_task)\n            response = user_proxy.initiate_chats(tasks)\n            result = \"### Output ###\\n\"+response[-1].summary if hasattr(response[-1], 'summary') else \"\"\n            if agentops_exists:\n                agentops.end_session(\"Success\")\n        else: # framework=crewai\n            if agentops_exists:\n                agentops.init(os.environ.get(\"AGENTOPS_API_KEY\"), tags=[\"crewai\"])\n\n            tasks_dict = {}\n\n            for role, details in config['roles'].items():\n                role_filled = details['role'].format(topic=topic)\n                goal_filled = details['goal'].format(topic=topic)\n                backstory_filled = details['backstory'].format(topic=topic)\n\n                # Adding tools to the agent if exists\n                agent_tools = [tools_dict[tool] for tool in details.get('tools', []) if tool in tools_dict]\n\n                llm_model = details.get('llm')  # Get the llm configuration\n                if llm_model:\n                    llm = PraisonAIModel(\n                        model=llm_model.get(\"model\", os.environ.get(\"MODEL_NAME\", \"openai/gpt-4o\")),\n                    ).get_model()\n                else:\n                    llm = PraisonAIModel().get_model()\n\n                function_calling_llm_model = details.get('function_calling_llm')\n                if function_calling_llm_model:\n                    function_calling_llm = PraisonAIModel(\n                        model=function_calling_llm_model.get(\"model\", os.environ.get(\"MODEL_NAME\", \"openai/gpt-4o\")),\n                    ).get_model()\n                else:\n                    function_calling_llm = PraisonAIModel().get_model()\n\n                agent = Agent(\n                    role=role_filled, \n                    goal=goal_filled, \n                    backstory=backstory_filled, \n                    tools=agent_tools, \n                    allow_delegation=details.get('allow_delegation', False),\n                    llm=llm,\n                    function_calling_llm=function_calling_llm,\n                    max_iter=details.get('max_iter', 15),\n                    max_rpm=details.get('max_rpm'),\n                    max_execution_time=details.get('max_execution_time'),\n                    verbose=details.get('verbose', True),\n                    cache=details.get('cache', True),\n                    system_template=details.get('system_template'),\n                    prompt_template=details.get('prompt_template'),\n                    response_template=details.get('response_template'),\n                )\n\n                # Set agent callback if provided\n                if self.agent_callback:\n                    agent.step_callback = self.agent_callback\n\n                agents[role] = agent\n\n                for task_name, task_details in details.get('tasks', {}).items():\n                    description_filled = task_details['description'].format(topic=topic)\n                    expected_output_filled = task_details['expected_output'].format(topic=topic)\n\n                    task = Task(\n                        description=description_filled,  # Clear, concise statement of what the task entails\n                        expected_output=expected_output_filled,  # Detailed description of what task's completion looks like\n                        agent=agent,  # The agent responsible for the task\n                        tools=task_details.get('tools', []),  # Functions or capabilities the agent can utilize\n                        async_execution=task_details.get('async_execution') if task_details.get('async_execution') is not None else False,  # Execute asynchronously if set\n                        context=[], ## TODO: \n                        config=task_details.get('config') if task_details.get('config') is not None else {},  # Additional configuration details\n                        output_json=task_details.get('output_json') if task_details.get('output_json') is not None else None,  # Outputs a JSON object\n                        output_pydantic=task_details.get('output_pydantic') if task_details.get('output_pydantic') is not None else None,  # Outputs a Pydantic model object\n                        output_file=task_details.get('output_file') if task_details.get('output_file') is not None else \"\",  # Saves the task output to a file\n                        callback=task_details.get('callback') if task_details.get('callback') is not None else None,  # Python callable executed with the task's output\n                        human_input=task_details.get('human_input') if task_details.get('human_input') is not None else False,  # Indicates if the task requires human feedback\n                        create_directory=task_details.get('create_directory') if task_details.get('create_directory') is not None else False  # Indicates if a directory needs to be created\n                    )\n\n                    # Set tool callback if provided\n                    if self.task_callback:\n                        task.callback = self.task_callback\n\n                    tasks.append(task)\n                    tasks_dict[task_name] = task\n\n            for role, details in config['roles'].items():\n                for task_name, task_details in details.get('tasks', {}).items():\n                    task = tasks_dict[task_name]\n                    context_tasks = [tasks_dict[ctx] for ctx in task_details.get('context', []) if ctx in tasks_dict]\n                    task.context = context_tasks\n\n            crew = Crew(\n                agents=list(agents.values()),\n                tasks=tasks,\n                verbose=2\n            )\n\n            self.logger.debug(\"Final Crew Configuration:\")\n            self.logger.debug(f\"Agents: {crew.agents}\")\n            self.logger.debug(f\"Tasks: {crew.tasks}\")\n\n            response = crew.kickoff()\n            result = f\"### Task Output ###\\n{response}\"\n            if agentops_exists:\n                agentops.end_session(\"Success\")\n        return result\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator.__init__","title":"<code>__init__(agent_file, framework, config_list, log_level=None, agent_callback=None, task_callback=None, agent_yaml=None)</code>","text":"<p>Initialize the AgentsGenerator object.</p> <p>Parameters:</p> Name Type Description Default <code>agent_file</code> <code>str</code> <p>The path to the agent file.</p> required <code>framework</code> <code>str</code> <p>The framework to be used for the agents.</p> required <code>config_list</code> <code>list</code> <p>A list of configurations for the agents.</p> required <code>log_level</code> <code>int</code> <p>The logging level to use. Defaults to logging.INFO.</p> <code>None</code> <code>agent_callback</code> <code>callable</code> <p>A callback function to be executed after each agent step.</p> <code>None</code> <code>task_callback</code> <code>callable</code> <p>A callback function to be executed after each tool run.</p> <code>None</code> <code>agent_yaml</code> <code>str</code> <p>The content of the YAML file. Defaults to None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>agent_file</code> <code>str</code> <p>The path to the agent file.</p> <code>framework</code> <code>str</code> <p>The framework to be used for the agents.</p> <code>config_list</code> <code>list</code> <p>A list of configurations for the agents.</p> <code>log_level</code> <code>int</code> <p>The logging level to use.</p> <code>agent_callback</code> <code>callable</code> <p>A callback function to be executed after each agent step.</p> <code>task_callback</code> <code>callable</code> <p>A callback function to be executed after each tool run.</p> Source code in <code>praisonai/agents_generator.py</code> <pre><code>def __init__(self, agent_file, framework, config_list, log_level=None, agent_callback=None, task_callback=None, agent_yaml=None):\n    \"\"\"\n    Initialize the AgentsGenerator object.\n\n    Parameters:\n        agent_file (str): The path to the agent file.\n        framework (str): The framework to be used for the agents.\n        config_list (list): A list of configurations for the agents.\n        log_level (int, optional): The logging level to use. Defaults to logging.INFO.\n        agent_callback (callable, optional): A callback function to be executed after each agent step.\n        task_callback (callable, optional): A callback function to be executed after each tool run.\n        agent_yaml (str, optional): The content of the YAML file. Defaults to None.\n\n    Attributes:\n        agent_file (str): The path to the agent file.\n        framework (str): The framework to be used for the agents.\n        config_list (list): A list of configurations for the agents.\n        log_level (int): The logging level to use.\n        agent_callback (callable, optional): A callback function to be executed after each agent step.\n        task_callback (callable, optional): A callback function to be executed after each tool run.\n    \"\"\"\n    self.agent_file = agent_file\n    self.framework = framework\n    self.config_list = config_list\n    self.log_level = log_level\n    self.agent_callback = agent_callback\n    self.task_callback = task_callback\n    self.agent_yaml = agent_yaml\n    self.log_level = log_level or logging.getLogger().getEffectiveLevel()\n    if self.log_level == logging.NOTSET:\n        self.log_level = os.environ.get('LOGLEVEL', 'INFO').upper()\n\n    logging.basicConfig(level=self.log_level, format='%(asctime)s - %(levelname)s - %(message)s')\n    self.logger = logging.getLogger(__name__)\n    self.logger.setLevel(self.log_level)\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator.generate_crew_and_kickoff","title":"<code>generate_crew_and_kickoff()</code>","text":"<p>Generates a crew of agents and initiates tasks based on the provided configuration.</p> <p>Parameters:</p> Name Type Description Default <code>agent_file</code> <code>str</code> <p>The path to the agent file.</p> required <code>framework</code> <code>str</code> <p>The framework to be used for the agents.</p> required <code>config_list</code> <code>list</code> <p>A list of configurations for the agents.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The output of the tasks performed by the crew of agents.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified agent file does not exist.</p> <p>This function first loads the agent configuration from the specified file. It then initializes the tools required for the agents based on the specified framework. If the specified framework is \"autogen\", it loads the LLM configuration dynamically and creates an AssistantAgent for each role in the configuration. It then adds tools to the agents if specified in the configuration. Finally, it prepares tasks for the agents based on the configuration and initiates the tasks using the crew of agents. If the specified framework is not \"autogen\", it creates a crew of agents and initiates tasks based on the configuration.</p> Source code in <code>praisonai/agents_generator.py</code> <pre><code>def generate_crew_and_kickoff(self):\n    \"\"\"\n    Generates a crew of agents and initiates tasks based on the provided configuration.\n\n    Parameters:\n        agent_file (str): The path to the agent file.\n        framework (str): The framework to be used for the agents.\n        config_list (list): A list of configurations for the agents.\n\n    Returns:\n        str: The output of the tasks performed by the crew of agents.\n\n    Raises:\n        FileNotFoundError: If the specified agent file does not exist.\n\n    This function first loads the agent configuration from the specified file. It then initializes the tools required for the agents based on the specified framework. If the specified framework is \"autogen\", it loads the LLM configuration dynamically and creates an AssistantAgent for each role in the configuration. It then adds tools to the agents if specified in the configuration. Finally, it prepares tasks for the agents based on the configuration and initiates the tasks using the crew of agents. If the specified framework is not \"autogen\", it creates a crew of agents and initiates tasks based on the configuration.\n    \"\"\"\n    if self.agent_yaml:\n        config = yaml.safe_load(self.agent_yaml)\n    else:\n        if self.agent_file == '/app/api:app' or self.agent_file == 'api:app':\n            self.agent_file = 'agents.yaml'\n        try:\n            with open(self.agent_file, 'r') as f:\n                config = yaml.safe_load(f)\n        except FileNotFoundError:\n            print(f\"File not found: {self.agent_file}\")\n            return\n\n    topic = config['topic']\n    tools_dict = {\n        'CodeDocsSearchTool': CodeDocsSearchTool(),\n        'CSVSearchTool': CSVSearchTool(),\n        'DirectorySearchTool': DirectorySearchTool(),\n        'DOCXSearchTool': DOCXSearchTool(),\n        'DirectoryReadTool': DirectoryReadTool(),\n        'FileReadTool': FileReadTool(),\n        # 'GithubSearchTool': GithubSearchTool(),\n        # 'SeperDevTool': SeperDevTool(),\n        'TXTSearchTool': TXTSearchTool(),\n        'JSONSearchTool': JSONSearchTool(),\n        'MDXSearchTool': MDXSearchTool(),\n        'PDFSearchTool': PDFSearchTool(),\n        # 'PGSearchTool': PGSearchTool(),\n        'RagTool': RagTool(),\n        'ScrapeElementFromWebsiteTool': ScrapeElementFromWebsiteTool(),\n        'ScrapeWebsiteTool': ScrapeWebsiteTool(),\n        'WebsiteSearchTool': WebsiteSearchTool(),\n        'XMLSearchTool': XMLSearchTool(),\n        'YoutubeChannelSearchTool': YoutubeChannelSearchTool(),\n        'YoutubeVideoSearchTool': YoutubeVideoSearchTool(),\n    }\n    root_directory = os.getcwd()\n    tools_py_path = os.path.join(root_directory, 'tools.py')\n    tools_dir_path = Path(root_directory) / 'tools'\n\n    if os.path.isfile(tools_py_path):\n        tools_dict.update(self.load_tools_from_module_class(tools_py_path))\n        self.logger.debug(\"tools.py exists in the root directory. Loading tools.py and skipping tools folder.\")\n    elif tools_dir_path.is_dir():\n        tools_dict.update(self.load_tools_from_module_class(tools_dir_path))\n        self.logger.debug(\"tools folder exists in the root directory\")\n\n    framework = self.framework or config.get('framework')\n\n    agents = {}\n    tasks = []\n    if framework == \"autogen\":\n        # Load the LLM configuration dynamically\n        # print(self.config_list)\n        llm_config = {\"config_list\": self.config_list}\n\n        if agentops_exists:\n            agentops.init(os.environ.get(\"AGENTOPS_API_KEY\"), tags=[\"autogen\"])\n        # Assuming the user proxy agent is set up as per your requirements\n        user_proxy = autogen.UserProxyAgent(\n            name=\"User\",\n            human_input_mode=\"NEVER\",\n            is_termination_msg=lambda x: (x.get(\"content\") or \"\").rstrip().rstrip(\".\").lower().endswith(\"terminate\") or \"TERMINATE\" in (x.get(\"content\") or \"\"),\n            code_execution_config={\n                \"work_dir\": \"coding\",\n                \"use_docker\": False,\n            },\n            # additional setup for the user proxy agent\n        )\n\n        for role, details in config['roles'].items():\n            agent_name = details['role'].format(topic=topic).replace(\"{topic}\", topic)\n            agent_goal = details['goal'].format(topic=topic)\n            # Creating an AssistantAgent for each role dynamically\n            agents[role] = autogen.AssistantAgent(\n                name=agent_name,\n                llm_config=llm_config,\n                system_message=details['backstory'].format(topic=topic)+\". Must Reply \\\"TERMINATE\\\" in the end when everything is done.\",\n            )\n            for tool in details.get('tools', []):\n                if tool in tools_dict:\n                    try:\n                        tool_class = globals()[f'autogen_{type(tools_dict[tool]).__name__}']\n                        print(f\"Found {tool_class.__name__} for {tool}\")\n                    except KeyError:\n                        print(f\"Warning: autogen_{type(tools_dict[tool]).__name__} function not found. Skipping this tool.\")\n                        continue\n                    tool_class(agents[role], user_proxy)\n\n            # Preparing tasks for initiate_chats\n            for task_name, task_details in details.get('tasks', {}).items():\n                description_filled = task_details['description'].format(topic=topic)\n                expected_output_filled = task_details['expected_output'].format(topic=topic)\n\n                chat_task = {\n                    \"recipient\": agents[role],\n                    \"message\": description_filled,\n                    \"summary_method\": \"last_msg\", \n                    # Additional fields like carryover can be added based on dependencies\n                }\n                tasks.append(chat_task)\n        response = user_proxy.initiate_chats(tasks)\n        result = \"### Output ###\\n\"+response[-1].summary if hasattr(response[-1], 'summary') else \"\"\n        if agentops_exists:\n            agentops.end_session(\"Success\")\n    else: # framework=crewai\n        if agentops_exists:\n            agentops.init(os.environ.get(\"AGENTOPS_API_KEY\"), tags=[\"crewai\"])\n\n        tasks_dict = {}\n\n        for role, details in config['roles'].items():\n            role_filled = details['role'].format(topic=topic)\n            goal_filled = details['goal'].format(topic=topic)\n            backstory_filled = details['backstory'].format(topic=topic)\n\n            # Adding tools to the agent if exists\n            agent_tools = [tools_dict[tool] for tool in details.get('tools', []) if tool in tools_dict]\n\n            llm_model = details.get('llm')  # Get the llm configuration\n            if llm_model:\n                llm = PraisonAIModel(\n                    model=llm_model.get(\"model\", os.environ.get(\"MODEL_NAME\", \"openai/gpt-4o\")),\n                ).get_model()\n            else:\n                llm = PraisonAIModel().get_model()\n\n            function_calling_llm_model = details.get('function_calling_llm')\n            if function_calling_llm_model:\n                function_calling_llm = PraisonAIModel(\n                    model=function_calling_llm_model.get(\"model\", os.environ.get(\"MODEL_NAME\", \"openai/gpt-4o\")),\n                ).get_model()\n            else:\n                function_calling_llm = PraisonAIModel().get_model()\n\n            agent = Agent(\n                role=role_filled, \n                goal=goal_filled, \n                backstory=backstory_filled, \n                tools=agent_tools, \n                allow_delegation=details.get('allow_delegation', False),\n                llm=llm,\n                function_calling_llm=function_calling_llm,\n                max_iter=details.get('max_iter', 15),\n                max_rpm=details.get('max_rpm'),\n                max_execution_time=details.get('max_execution_time'),\n                verbose=details.get('verbose', True),\n                cache=details.get('cache', True),\n                system_template=details.get('system_template'),\n                prompt_template=details.get('prompt_template'),\n                response_template=details.get('response_template'),\n            )\n\n            # Set agent callback if provided\n            if self.agent_callback:\n                agent.step_callback = self.agent_callback\n\n            agents[role] = agent\n\n            for task_name, task_details in details.get('tasks', {}).items():\n                description_filled = task_details['description'].format(topic=topic)\n                expected_output_filled = task_details['expected_output'].format(topic=topic)\n\n                task = Task(\n                    description=description_filled,  # Clear, concise statement of what the task entails\n                    expected_output=expected_output_filled,  # Detailed description of what task's completion looks like\n                    agent=agent,  # The agent responsible for the task\n                    tools=task_details.get('tools', []),  # Functions or capabilities the agent can utilize\n                    async_execution=task_details.get('async_execution') if task_details.get('async_execution') is not None else False,  # Execute asynchronously if set\n                    context=[], ## TODO: \n                    config=task_details.get('config') if task_details.get('config') is not None else {},  # Additional configuration details\n                    output_json=task_details.get('output_json') if task_details.get('output_json') is not None else None,  # Outputs a JSON object\n                    output_pydantic=task_details.get('output_pydantic') if task_details.get('output_pydantic') is not None else None,  # Outputs a Pydantic model object\n                    output_file=task_details.get('output_file') if task_details.get('output_file') is not None else \"\",  # Saves the task output to a file\n                    callback=task_details.get('callback') if task_details.get('callback') is not None else None,  # Python callable executed with the task's output\n                    human_input=task_details.get('human_input') if task_details.get('human_input') is not None else False,  # Indicates if the task requires human feedback\n                    create_directory=task_details.get('create_directory') if task_details.get('create_directory') is not None else False  # Indicates if a directory needs to be created\n                )\n\n                # Set tool callback if provided\n                if self.task_callback:\n                    task.callback = self.task_callback\n\n                tasks.append(task)\n                tasks_dict[task_name] = task\n\n        for role, details in config['roles'].items():\n            for task_name, task_details in details.get('tasks', {}).items():\n                task = tasks_dict[task_name]\n                context_tasks = [tasks_dict[ctx] for ctx in task_details.get('context', []) if ctx in tasks_dict]\n                task.context = context_tasks\n\n        crew = Crew(\n            agents=list(agents.values()),\n            tasks=tasks,\n            verbose=2\n        )\n\n        self.logger.debug(\"Final Crew Configuration:\")\n        self.logger.debug(f\"Agents: {crew.agents}\")\n        self.logger.debug(f\"Tasks: {crew.tasks}\")\n\n        response = crew.kickoff()\n        result = f\"### Task Output ###\\n{response}\"\n        if agentops_exists:\n            agentops.end_session(\"Success\")\n    return result\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator.is_function_or_decorated","title":"<code>is_function_or_decorated(obj)</code>","text":"<p>Checks if the given object is a function or has a call method.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>The object to be checked.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the object is a function or has a call method, False otherwise.</p> Source code in <code>praisonai/agents_generator.py</code> <pre><code>def is_function_or_decorated(self, obj):\n    \"\"\"\n    Checks if the given object is a function or has a __call__ method.\n\n    Parameters:\n        obj (object): The object to be checked.\n\n    Returns:\n        bool: True if the object is a function or has a __call__ method, False otherwise.\n    \"\"\"\n    return inspect.isfunction(obj) or hasattr(obj, '__call__')\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator.load_tools_from_module","title":"<code>load_tools_from_module(module_path)</code>","text":"<p>Loads tools from a specified module path.</p> <p>Parameters:</p> Name Type Description Default <code>module_path</code> <code>str</code> <p>The path to the module containing the tools.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the names of the tools as keys and the corresponding functions or objects as values.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified module path does not exist.</p> Source code in <code>praisonai/agents_generator.py</code> <pre><code>def load_tools_from_module(self, module_path):\n    \"\"\"\n    Loads tools from a specified module path.\n\n    Parameters:\n        module_path (str): The path to the module containing the tools.\n\n    Returns:\n        dict: A dictionary containing the names of the tools as keys and the corresponding functions or objects as values.\n\n    Raises:\n        FileNotFoundError: If the specified module path does not exist.\n    \"\"\"\n    spec = importlib.util.spec_from_file_location(\"tools_module\", module_path)\n    module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(module)\n    return {name: obj for name, obj in inspect.getmembers(module, self.is_function_or_decorated)}\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator.load_tools_from_module_class","title":"<code>load_tools_from_module_class(module_path)</code>","text":"<p>Loads tools from a specified module path containing classes that inherit from BaseTool or are part of langchain_community.tools package.</p> <p>Parameters:</p> Name Type Description Default <code>module_path</code> <code>str</code> <p>The path to the module containing the tools.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified module path does not exist.</p> Source code in <code>praisonai/agents_generator.py</code> <pre><code>def load_tools_from_module_class(self, module_path):\n    \"\"\"\n    Loads tools from a specified module path containing classes that inherit from BaseTool or are part of langchain_community.tools package.\n\n    Parameters:\n        module_path (str): The path to the module containing the tools.\n\n    Returns:\n        dict: A dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.\n\n    Raises:\n        FileNotFoundError: If the specified module path does not exist.\n    \"\"\"\n    spec = importlib.util.spec_from_file_location(\"tools_module\", module_path)\n    module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(module)\n    return {name: obj() for name, obj in inspect.getmembers(module, lambda x: inspect.isclass(x) and (x.__module__.startswith('langchain_community.tools') or issubclass(x, BaseTool)) and x is not BaseTool)}\n</code></pre>"},{"location":"api/#praisonai.agents_generator.AgentsGenerator.load_tools_from_package","title":"<code>load_tools_from_package(package_path)</code>","text":"<p>Loads tools from a specified package path containing modules with functions or classes.</p> <p>Parameters:</p> Name Type Description Default <code>package_path</code> <code>str</code> <p>The path to the package containing the tools.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified package path does not exist.</p> <p>This function iterates through all the .py files in the specified package path, excluding those that start with \"__\". For each file, it imports the corresponding module and checks if it contains any functions or classes that can be loaded as tools. The function then returns a dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.</p> Source code in <code>praisonai/agents_generator.py</code> <pre><code>def load_tools_from_package(self, package_path):\n    \"\"\"\n    Loads tools from a specified package path containing modules with functions or classes.\n\n    Parameters:\n        package_path (str): The path to the package containing the tools.\n\n    Returns:\n        dict: A dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.\n\n    Raises:\n        FileNotFoundError: If the specified package path does not exist.\n\n    This function iterates through all the .py files in the specified package path, excluding those that start with \"__\". For each file, it imports the corresponding module and checks if it contains any functions or classes that can be loaded as tools. The function then returns a dictionary containing the names of the tools as keys and the corresponding initialized instances of the classes as values.\n    \"\"\"\n    tools_dict = {}\n    for module_file in os.listdir(package_path):\n        if module_file.endswith('.py') and not module_file.startswith('__'):\n            module_name = f\"{package_path.name}.{module_file[:-3]}\"  # Remove .py for import\n            module = importlib.import_module(module_name)\n            for name, obj in inspect.getmembers(module, self.is_function_or_decorated):\n                tools_dict[name] = obj\n    return tools_dict\n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI","title":"<code>PraisonAI</code>","text":"Source code in <code>praisonai/cli.py</code> <pre><code>class PraisonAI:\n    def __init__(self, agent_file=\"agents.yaml\", framework=\"\", auto=False, init=False, agent_yaml=None):\n        \"\"\"\n        Initialize the PraisonAI object with default parameters.\n\n        Parameters:\n            agent_file (str): The default agent file to use. Defaults to \"agents.yaml\".\n            framework (str): The default framework to use. Defaults to \"crewai\".\n            auto (bool): A flag indicating whether to enable auto mode. Defaults to False.\n            init (bool): A flag indicating whether to enable initialization mode. Defaults to False.\n\n        Attributes:\n            config_list (list): A list of configuration dictionaries for the OpenAI API.\n            agent_file (str): The agent file to use.\n            framework (str): The framework to use.\n            auto (bool): A flag indicating whether to enable auto mode.\n            init (bool): A flag indicating whether to enable initialization mode.\n            agent_yaml (str, optional): The content of the YAML file. Defaults to None.\n        \"\"\"\n        self.agent_yaml = agent_yaml\n        self.config_list = [\n            {\n                'model': os.environ.get(\"OPENAI_MODEL_NAME\", \"gpt-4o\"),\n                'base_url': os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n                'api_key': os.environ.get(\"OPENAI_API_KEY\")\n            }\n        ]\n        self.agent_file = agent_file\n        self.framework = framework\n        self.auto = auto\n        self.init = init\n\n    def run(self):\n        \"\"\"\n        Run the PraisonAI application.\n        \"\"\"\n        self.main()\n\n    def main(self):\n        \"\"\"\n        The main function of the PraisonAI object. It parses the command-line arguments,\n        initializes the necessary attributes, and then calls the appropriate methods based on the\n        provided arguments.\n\n        Args:\n            self (PraisonAI): An instance of the PraisonAI class.\n\n        Returns:\n            Any: Depending on the arguments provided, the function may return a result from the\n            AgentsGenerator, a deployment result from the CloudDeployer, or a message indicating\n            the successful creation of a file.\n        \"\"\"\n        args = self.parse_args()\n        if args is None:\n            agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list)\n            result = agents_generator.generate_crew_and_kickoff()\n            return result\n        if args.deploy:\n            from .deploy import CloudDeployer\n            deployer = CloudDeployer()\n            deployer.run_commands()\n            return\n\n        if getattr(args, 'chat', False):\n            self.create_chainlit_chat_interface()\n            return\n\n        if getattr(args, 'code', False):\n            self.create_code_interface()\n            return\n\n        invocation_cmd = \"praisonai\"\n        version_string = f\"PraisonAI version {__version__}\"\n\n        self.framework = args.framework or self.framework \n\n        if args.agent_file:\n            if args.agent_file.startswith(\"tests.test\"): # Argument used for testing purposes. eg: python -m unittest tests.test \n                print(\"test\")\n            else:\n                self.agent_file = args.agent_file\n\n\n        if args.auto or args.init:\n            temp_topic = ' '.join(args.auto) if args.auto else ' '.join(args.init)\n            self.topic = temp_topic\n        elif self.auto or self.init:  # Use the auto attribute if args.auto is not provided\n            self.topic = self.auto\n\n        if args.auto or self.auto:\n            self.agent_file = \"test.yaml\"\n            generator = AutoGenerator(topic=self.topic , framework=self.framework, agent_file=self.agent_file)\n            self.agent_file = generator.generate()\n            agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list)\n            result = agents_generator.generate_crew_and_kickoff()\n            return result\n        elif args.init or self.init:\n            self.agent_file = \"agents.yaml\"\n            generator = AutoGenerator(topic=self.topic , framework=self.framework, agent_file=self.agent_file)\n            self.agent_file = generator.generate()\n            print(\"File {} created successfully\".format(self.agent_file))\n            return \"File {} created successfully\".format(self.agent_file)\n\n        if args.ui:\n            if args.ui == \"gradio\":\n                self.create_gradio_interface()\n            elif args.ui == \"chainlit\":\n                self.create_chainlit_interface()\n            else:\n                # Modify below code to allow default ui\n                agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list, agent_yaml=self.agent_yaml)\n                result = agents_generator.generate_crew_and_kickoff()\n                return result\n        else:\n            agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list, agent_yaml=self.agent_yaml)\n            result = agents_generator.generate_crew_and_kickoff()\n            return result\n\n    def parse_args(self):\n        \"\"\"\n        Parse the command-line arguments for the PraisonAI CLI.\n\n        Args:\n            self (PraisonAI): An instance of the PraisonAI class.\n\n        Returns:\n            argparse.Namespace: An object containing the parsed command-line arguments.\n\n        Raises:\n            argparse.ArgumentError: If the arguments provided are invalid.\n\n        Example:\n            &gt;&gt;&gt; args = praison_ai.parse_args()\n            &gt;&gt;&gt; print(args.agent_file)  # Output: 'agents.yaml'\n        \"\"\"\n        parser = argparse.ArgumentParser(prog=\"praisonai\", description=\"praisonAI command-line interface\")\n        parser.add_argument(\"--framework\", choices=[\"crewai\", \"autogen\"], help=\"Specify the framework\")\n        parser.add_argument(\"--ui\", choices=[\"chainlit\", \"gradio\"], help=\"Specify the UI framework (gradio or chainlit).\")\n        parser.add_argument(\"--auto\", nargs=argparse.REMAINDER, help=\"Enable auto mode and pass arguments for it\")\n        parser.add_argument(\"--init\", nargs=argparse.REMAINDER, help=\"Enable auto mode and pass arguments for it\")\n        parser.add_argument(\"agent_file\", nargs=\"?\", help=\"Specify the agent file\")\n        parser.add_argument(\"--deploy\", action=\"store_true\", help=\"Deploy the application\")  # New argument\n        args, unknown_args = parser.parse_known_args()\n\n        if unknown_args and unknown_args[0] == '-b' and unknown_args[1] == 'api:app':\n            args.agent_file = 'agents.yaml'\n        if args.agent_file == 'api:app' or args.agent_file == '/app/api:app':\n            args.agent_file = 'agents.yaml'\n        if args.agent_file == 'ui':\n            args.ui = 'chainlit'\n        if args.agent_file == 'chat':\n            args.ui = 'chainlit'\n            args.chat = True\n        if args.agent_file == 'code':\n            args.ui = 'chainlit'\n            args.code = True\n\n        return args\n\n    def create_chainlit_chat_interface(self):\n        \"\"\"\n        Create a Chainlit interface for the chat application.\n\n        This function sets up a Chainlit application that listens for messages.\n        When a message is received, it runs PraisonAI with the provided message as the topic.\n        The generated agents are then used to perform tasks.\n\n        Returns:\n            None: This function does not return any value. It starts the Chainlit application.\n        \"\"\"\n        if CHAINLIT_AVAILABLE:\n            import praisonai\n            os.environ[\"CHAINLIT_PORT\"] = \"8084\"\n            public_folder = os.path.join(os.path.dirname(praisonai.__file__), 'public')\n            if not os.path.exists(\"public\"):  # Check if the folder exists in the current directory\n                if os.path.exists(public_folder):\n                    shutil.copytree(public_folder, 'public', dirs_exist_ok=True)\n                    logging.info(\"Public folder copied successfully!\")\n                else:\n                    logging.info(\"Public folder not found in the package.\")\n            else:\n                logging.info(\"Public folder already exists.\")\n            chat_ui_path = os.path.join(os.path.dirname(praisonai.__file__), 'ui', 'chat.py')\n            chainlit_run([chat_ui_path])\n        else:\n            print(\"ERROR: Chat UI is not installed. Please install it with 'pip install \\\"praisonai\\[chat]\\\"' to use the chat UI.\")\n\n    def create_code_interface(self):\n        \"\"\"\n        Create a Chainlit interface for the code application.\n\n        This function sets up a Chainlit application that listens for messages.\n        When a message is received, it runs PraisonAI with the provided message as the topic.\n        The generated agents are then used to perform tasks.\n\n        Returns:\n            None: This function does not return any value. It starts the Chainlit application.\n        \"\"\"\n        if CHAINLIT_AVAILABLE:\n            import praisonai\n            os.environ[\"CHAINLIT_PORT\"] = \"8086\"\n            public_folder = os.path.join(os.path.dirname(praisonai.__file__), 'public')\n            if not os.path.exists(\"public\"):  # Check if the folder exists in the current directory\n                if os.path.exists(public_folder):\n                    shutil.copytree(public_folder, 'public', dirs_exist_ok=True)\n                    logging.info(\"Public folder copied successfully!\")\n                else:\n                    logging.info(\"Public folder not found in the package.\")\n            else:\n                logging.info(\"Public folder already exists.\")\n            code_ui_path = os.path.join(os.path.dirname(praisonai.__file__), 'ui', 'code.py')\n            chainlit_run([code_ui_path])\n        else:\n            print(\"ERROR: Code UI is not installed. Please install it with 'pip install \\\"praisonai\\[code]\\\"' to use the code UI.\")\n\n    def create_gradio_interface(self):\n        \"\"\"\n        Create a Gradio interface for generating agents and performing tasks.\n\n        Args:\n            self (PraisonAI): An instance of the PraisonAI class.\n\n        Returns:\n            None: This method does not return any value. It launches the Gradio interface.\n\n        Raises:\n            None: This method does not raise any exceptions.\n\n        Example:\n            &gt;&gt;&gt; praison_ai.create_gradio_interface()\n        \"\"\"\n        if GRADIO_AVAILABLE:\n            def generate_crew_and_kickoff_interface(auto_args, framework):\n                \"\"\"\n                Generate a crew and kick off tasks based on the provided auto arguments and framework.\n\n                Args:\n                    auto_args (list): Topic.\n                    framework (str): The framework to use for generating agents.\n\n                Returns:\n                    str: A string representing the result of generating the crew and kicking off tasks.\n\n                Raises:\n                    None: This method does not raise any exceptions.\n\n                Example:\n                    &gt;&gt;&gt; result = generate_crew_and_kickoff_interface(\"Create a movie about Cat in Mars\", \"crewai\")\n                    &gt;&gt;&gt; print(result)\n                \"\"\"\n                self.framework = framework\n                self.agent_file = \"test.yaml\"\n                generator = AutoGenerator(topic=auto_args , framework=self.framework)\n                self.agent_file = generator.generate()\n                agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list)\n                result = agents_generator.generate_crew_and_kickoff()\n                return result\n\n            gr.Interface(\n                fn=generate_crew_and_kickoff_interface,\n                inputs=[gr.Textbox(lines=2, label=\"Auto Args\"), gr.Dropdown(choices=[\"crewai\", \"autogen\"], label=\"Framework\")],\n                outputs=\"textbox\",\n                title=\"Praison AI Studio\",\n                description=\"Create Agents and perform tasks\",\n                theme=\"default\"\n            ).launch()\n        else:\n            print(\"ERROR: Gradio is not installed. Please install it with 'pip install gradio' to use this feature.\") \n\n    def create_chainlit_interface(self):\n        \"\"\"\n        Create a Chainlit interface for generating agents and performing tasks.\n\n        This function sets up a Chainlit application that listens for messages.\n        When a message is received, it runs PraisonAI with the provided message as the topic.\n        The generated agents are then used to perform tasks.\n\n        Returns:\n            None: This function does not return any value. It starts the Chainlit application.\n        \"\"\"\n        if CHAINLIT_AVAILABLE:\n            import praisonai\n            os.environ[\"CHAINLIT_PORT\"] = \"8082\"\n            # Get the path to the 'public' folder within the package\n            public_folder = os.path.join(os.path.dirname(praisonai.__file__), 'public')\n            if not os.path.exists(\"public\"):  # Check if the folder exists in the current directory\n                if os.path.exists(public_folder):\n                    shutil.copytree(public_folder, 'public', dirs_exist_ok=True)\n                    logging.info(\"Public folder copied successfully!\")\n                else:\n                    logging.info(\"Public folder not found in the package.\")\n            else:\n                logging.info(\"Public folder already exists.\")\n            chainlit_ui_path = os.path.join(os.path.dirname(praisonai.__file__), 'chainlit_ui.py')\n            chainlit_run([chainlit_ui_path])\n        else:\n            print(\"ERROR: Chainlit is not installed. Please install it with 'pip install \\\"praisonai\\[ui]\\\"' to use the UI.\")        \n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.__init__","title":"<code>__init__(agent_file='agents.yaml', framework='', auto=False, init=False, agent_yaml=None)</code>","text":"<p>Initialize the PraisonAI object with default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>agent_file</code> <code>str</code> <p>The default agent file to use. Defaults to \"agents.yaml\".</p> <code>'agents.yaml'</code> <code>framework</code> <code>str</code> <p>The default framework to use. Defaults to \"crewai\".</p> <code>''</code> <code>auto</code> <code>bool</code> <p>A flag indicating whether to enable auto mode. Defaults to False.</p> <code>False</code> <code>init</code> <code>bool</code> <p>A flag indicating whether to enable initialization mode. Defaults to False.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>config_list</code> <code>list</code> <p>A list of configuration dictionaries for the OpenAI API.</p> <code>agent_file</code> <code>str</code> <p>The agent file to use.</p> <code>framework</code> <code>str</code> <p>The framework to use.</p> <code>auto</code> <code>bool</code> <p>A flag indicating whether to enable auto mode.</p> <code>init</code> <code>bool</code> <p>A flag indicating whether to enable initialization mode.</p> <code>agent_yaml</code> <code>str</code> <p>The content of the YAML file. Defaults to None.</p> Source code in <code>praisonai/cli.py</code> <pre><code>def __init__(self, agent_file=\"agents.yaml\", framework=\"\", auto=False, init=False, agent_yaml=None):\n    \"\"\"\n    Initialize the PraisonAI object with default parameters.\n\n    Parameters:\n        agent_file (str): The default agent file to use. Defaults to \"agents.yaml\".\n        framework (str): The default framework to use. Defaults to \"crewai\".\n        auto (bool): A flag indicating whether to enable auto mode. Defaults to False.\n        init (bool): A flag indicating whether to enable initialization mode. Defaults to False.\n\n    Attributes:\n        config_list (list): A list of configuration dictionaries for the OpenAI API.\n        agent_file (str): The agent file to use.\n        framework (str): The framework to use.\n        auto (bool): A flag indicating whether to enable auto mode.\n        init (bool): A flag indicating whether to enable initialization mode.\n        agent_yaml (str, optional): The content of the YAML file. Defaults to None.\n    \"\"\"\n    self.agent_yaml = agent_yaml\n    self.config_list = [\n        {\n            'model': os.environ.get(\"OPENAI_MODEL_NAME\", \"gpt-4o\"),\n            'base_url': os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n            'api_key': os.environ.get(\"OPENAI_API_KEY\")\n        }\n    ]\n    self.agent_file = agent_file\n    self.framework = framework\n    self.auto = auto\n    self.init = init\n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.create_chainlit_chat_interface","title":"<code>create_chainlit_chat_interface()</code>","text":"<p>Create a Chainlit interface for the chat application.</p> <p>This function sets up a Chainlit application that listens for messages. When a message is received, it runs PraisonAI with the provided message as the topic. The generated agents are then used to perform tasks.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return any value. It starts the Chainlit application.</p> Source code in <code>praisonai/cli.py</code> <pre><code>def create_chainlit_chat_interface(self):\n    \"\"\"\n    Create a Chainlit interface for the chat application.\n\n    This function sets up a Chainlit application that listens for messages.\n    When a message is received, it runs PraisonAI with the provided message as the topic.\n    The generated agents are then used to perform tasks.\n\n    Returns:\n        None: This function does not return any value. It starts the Chainlit application.\n    \"\"\"\n    if CHAINLIT_AVAILABLE:\n        import praisonai\n        os.environ[\"CHAINLIT_PORT\"] = \"8084\"\n        public_folder = os.path.join(os.path.dirname(praisonai.__file__), 'public')\n        if not os.path.exists(\"public\"):  # Check if the folder exists in the current directory\n            if os.path.exists(public_folder):\n                shutil.copytree(public_folder, 'public', dirs_exist_ok=True)\n                logging.info(\"Public folder copied successfully!\")\n            else:\n                logging.info(\"Public folder not found in the package.\")\n        else:\n            logging.info(\"Public folder already exists.\")\n        chat_ui_path = os.path.join(os.path.dirname(praisonai.__file__), 'ui', 'chat.py')\n        chainlit_run([chat_ui_path])\n    else:\n        print(\"ERROR: Chat UI is not installed. Please install it with 'pip install \\\"praisonai\\[chat]\\\"' to use the chat UI.\")\n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.create_chainlit_interface","title":"<code>create_chainlit_interface()</code>","text":"<p>Create a Chainlit interface for generating agents and performing tasks.</p> <p>This function sets up a Chainlit application that listens for messages. When a message is received, it runs PraisonAI with the provided message as the topic. The generated agents are then used to perform tasks.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return any value. It starts the Chainlit application.</p> Source code in <code>praisonai/cli.py</code> <pre><code>def create_chainlit_interface(self):\n    \"\"\"\n    Create a Chainlit interface for generating agents and performing tasks.\n\n    This function sets up a Chainlit application that listens for messages.\n    When a message is received, it runs PraisonAI with the provided message as the topic.\n    The generated agents are then used to perform tasks.\n\n    Returns:\n        None: This function does not return any value. It starts the Chainlit application.\n    \"\"\"\n    if CHAINLIT_AVAILABLE:\n        import praisonai\n        os.environ[\"CHAINLIT_PORT\"] = \"8082\"\n        # Get the path to the 'public' folder within the package\n        public_folder = os.path.join(os.path.dirname(praisonai.__file__), 'public')\n        if not os.path.exists(\"public\"):  # Check if the folder exists in the current directory\n            if os.path.exists(public_folder):\n                shutil.copytree(public_folder, 'public', dirs_exist_ok=True)\n                logging.info(\"Public folder copied successfully!\")\n            else:\n                logging.info(\"Public folder not found in the package.\")\n        else:\n            logging.info(\"Public folder already exists.\")\n        chainlit_ui_path = os.path.join(os.path.dirname(praisonai.__file__), 'chainlit_ui.py')\n        chainlit_run([chainlit_ui_path])\n    else:\n        print(\"ERROR: Chainlit is not installed. Please install it with 'pip install \\\"praisonai\\[ui]\\\"' to use the UI.\")        \n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.create_code_interface","title":"<code>create_code_interface()</code>","text":"<p>Create a Chainlit interface for the code application.</p> <p>This function sets up a Chainlit application that listens for messages. When a message is received, it runs PraisonAI with the provided message as the topic. The generated agents are then used to perform tasks.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return any value. It starts the Chainlit application.</p> Source code in <code>praisonai/cli.py</code> <pre><code>def create_code_interface(self):\n    \"\"\"\n    Create a Chainlit interface for the code application.\n\n    This function sets up a Chainlit application that listens for messages.\n    When a message is received, it runs PraisonAI with the provided message as the topic.\n    The generated agents are then used to perform tasks.\n\n    Returns:\n        None: This function does not return any value. It starts the Chainlit application.\n    \"\"\"\n    if CHAINLIT_AVAILABLE:\n        import praisonai\n        os.environ[\"CHAINLIT_PORT\"] = \"8086\"\n        public_folder = os.path.join(os.path.dirname(praisonai.__file__), 'public')\n        if not os.path.exists(\"public\"):  # Check if the folder exists in the current directory\n            if os.path.exists(public_folder):\n                shutil.copytree(public_folder, 'public', dirs_exist_ok=True)\n                logging.info(\"Public folder copied successfully!\")\n            else:\n                logging.info(\"Public folder not found in the package.\")\n        else:\n            logging.info(\"Public folder already exists.\")\n        code_ui_path = os.path.join(os.path.dirname(praisonai.__file__), 'ui', 'code.py')\n        chainlit_run([code_ui_path])\n    else:\n        print(\"ERROR: Code UI is not installed. Please install it with 'pip install \\\"praisonai\\[code]\\\"' to use the code UI.\")\n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.create_gradio_interface","title":"<code>create_gradio_interface()</code>","text":"<p>Create a Gradio interface for generating agents and performing tasks.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>PraisonAI</code> <p>An instance of the PraisonAI class.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>This method does not return any value. It launches the Gradio interface.</p> <p>Raises:</p> Type Description <code>None</code> <p>This method does not raise any exceptions.</p> Example <p>praison_ai.create_gradio_interface()</p> Source code in <code>praisonai/cli.py</code> <pre><code>def create_gradio_interface(self):\n    \"\"\"\n    Create a Gradio interface for generating agents and performing tasks.\n\n    Args:\n        self (PraisonAI): An instance of the PraisonAI class.\n\n    Returns:\n        None: This method does not return any value. It launches the Gradio interface.\n\n    Raises:\n        None: This method does not raise any exceptions.\n\n    Example:\n        &gt;&gt;&gt; praison_ai.create_gradio_interface()\n    \"\"\"\n    if GRADIO_AVAILABLE:\n        def generate_crew_and_kickoff_interface(auto_args, framework):\n            \"\"\"\n            Generate a crew and kick off tasks based on the provided auto arguments and framework.\n\n            Args:\n                auto_args (list): Topic.\n                framework (str): The framework to use for generating agents.\n\n            Returns:\n                str: A string representing the result of generating the crew and kicking off tasks.\n\n            Raises:\n                None: This method does not raise any exceptions.\n\n            Example:\n                &gt;&gt;&gt; result = generate_crew_and_kickoff_interface(\"Create a movie about Cat in Mars\", \"crewai\")\n                &gt;&gt;&gt; print(result)\n            \"\"\"\n            self.framework = framework\n            self.agent_file = \"test.yaml\"\n            generator = AutoGenerator(topic=auto_args , framework=self.framework)\n            self.agent_file = generator.generate()\n            agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list)\n            result = agents_generator.generate_crew_and_kickoff()\n            return result\n\n        gr.Interface(\n            fn=generate_crew_and_kickoff_interface,\n            inputs=[gr.Textbox(lines=2, label=\"Auto Args\"), gr.Dropdown(choices=[\"crewai\", \"autogen\"], label=\"Framework\")],\n            outputs=\"textbox\",\n            title=\"Praison AI Studio\",\n            description=\"Create Agents and perform tasks\",\n            theme=\"default\"\n        ).launch()\n    else:\n        print(\"ERROR: Gradio is not installed. Please install it with 'pip install gradio' to use this feature.\") \n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.main","title":"<code>main()</code>","text":"<p>The main function of the PraisonAI object. It parses the command-line arguments, initializes the necessary attributes, and then calls the appropriate methods based on the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>PraisonAI</code> <p>An instance of the PraisonAI class.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Depending on the arguments provided, the function may return a result from the</p> <p>AgentsGenerator, a deployment result from the CloudDeployer, or a message indicating</p> <p>the successful creation of a file.</p> Source code in <code>praisonai/cli.py</code> <pre><code>def main(self):\n    \"\"\"\n    The main function of the PraisonAI object. It parses the command-line arguments,\n    initializes the necessary attributes, and then calls the appropriate methods based on the\n    provided arguments.\n\n    Args:\n        self (PraisonAI): An instance of the PraisonAI class.\n\n    Returns:\n        Any: Depending on the arguments provided, the function may return a result from the\n        AgentsGenerator, a deployment result from the CloudDeployer, or a message indicating\n        the successful creation of a file.\n    \"\"\"\n    args = self.parse_args()\n    if args is None:\n        agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list)\n        result = agents_generator.generate_crew_and_kickoff()\n        return result\n    if args.deploy:\n        from .deploy import CloudDeployer\n        deployer = CloudDeployer()\n        deployer.run_commands()\n        return\n\n    if getattr(args, 'chat', False):\n        self.create_chainlit_chat_interface()\n        return\n\n    if getattr(args, 'code', False):\n        self.create_code_interface()\n        return\n\n    invocation_cmd = \"praisonai\"\n    version_string = f\"PraisonAI version {__version__}\"\n\n    self.framework = args.framework or self.framework \n\n    if args.agent_file:\n        if args.agent_file.startswith(\"tests.test\"): # Argument used for testing purposes. eg: python -m unittest tests.test \n            print(\"test\")\n        else:\n            self.agent_file = args.agent_file\n\n\n    if args.auto or args.init:\n        temp_topic = ' '.join(args.auto) if args.auto else ' '.join(args.init)\n        self.topic = temp_topic\n    elif self.auto or self.init:  # Use the auto attribute if args.auto is not provided\n        self.topic = self.auto\n\n    if args.auto or self.auto:\n        self.agent_file = \"test.yaml\"\n        generator = AutoGenerator(topic=self.topic , framework=self.framework, agent_file=self.agent_file)\n        self.agent_file = generator.generate()\n        agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list)\n        result = agents_generator.generate_crew_and_kickoff()\n        return result\n    elif args.init or self.init:\n        self.agent_file = \"agents.yaml\"\n        generator = AutoGenerator(topic=self.topic , framework=self.framework, agent_file=self.agent_file)\n        self.agent_file = generator.generate()\n        print(\"File {} created successfully\".format(self.agent_file))\n        return \"File {} created successfully\".format(self.agent_file)\n\n    if args.ui:\n        if args.ui == \"gradio\":\n            self.create_gradio_interface()\n        elif args.ui == \"chainlit\":\n            self.create_chainlit_interface()\n        else:\n            # Modify below code to allow default ui\n            agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list, agent_yaml=self.agent_yaml)\n            result = agents_generator.generate_crew_and_kickoff()\n            return result\n    else:\n        agents_generator = AgentsGenerator(self.agent_file, self.framework, self.config_list, agent_yaml=self.agent_yaml)\n        result = agents_generator.generate_crew_and_kickoff()\n        return result\n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse the command-line arguments for the PraisonAI CLI.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>PraisonAI</code> <p>An instance of the PraisonAI class.</p> required <p>Returns:</p> Type Description <p>argparse.Namespace: An object containing the parsed command-line arguments.</p> <p>Raises:</p> Type Description <code>ArgumentError</code> <p>If the arguments provided are invalid.</p> Example <p>args = praison_ai.parse_args() print(args.agent_file)  # Output: 'agents.yaml'</p> Source code in <code>praisonai/cli.py</code> <pre><code>def parse_args(self):\n    \"\"\"\n    Parse the command-line arguments for the PraisonAI CLI.\n\n    Args:\n        self (PraisonAI): An instance of the PraisonAI class.\n\n    Returns:\n        argparse.Namespace: An object containing the parsed command-line arguments.\n\n    Raises:\n        argparse.ArgumentError: If the arguments provided are invalid.\n\n    Example:\n        &gt;&gt;&gt; args = praison_ai.parse_args()\n        &gt;&gt;&gt; print(args.agent_file)  # Output: 'agents.yaml'\n    \"\"\"\n    parser = argparse.ArgumentParser(prog=\"praisonai\", description=\"praisonAI command-line interface\")\n    parser.add_argument(\"--framework\", choices=[\"crewai\", \"autogen\"], help=\"Specify the framework\")\n    parser.add_argument(\"--ui\", choices=[\"chainlit\", \"gradio\"], help=\"Specify the UI framework (gradio or chainlit).\")\n    parser.add_argument(\"--auto\", nargs=argparse.REMAINDER, help=\"Enable auto mode and pass arguments for it\")\n    parser.add_argument(\"--init\", nargs=argparse.REMAINDER, help=\"Enable auto mode and pass arguments for it\")\n    parser.add_argument(\"agent_file\", nargs=\"?\", help=\"Specify the agent file\")\n    parser.add_argument(\"--deploy\", action=\"store_true\", help=\"Deploy the application\")  # New argument\n    args, unknown_args = parser.parse_known_args()\n\n    if unknown_args and unknown_args[0] == '-b' and unknown_args[1] == 'api:app':\n        args.agent_file = 'agents.yaml'\n    if args.agent_file == 'api:app' or args.agent_file == '/app/api:app':\n        args.agent_file = 'agents.yaml'\n    if args.agent_file == 'ui':\n        args.ui = 'chainlit'\n    if args.agent_file == 'chat':\n        args.ui = 'chainlit'\n        args.chat = True\n    if args.agent_file == 'code':\n        args.ui = 'chainlit'\n        args.code = True\n\n    return args\n</code></pre>"},{"location":"api/#praisonai.cli.PraisonAI.run","title":"<code>run()</code>","text":"<p>Run the PraisonAI application.</p> Source code in <code>praisonai/cli.py</code> <pre><code>def run(self):\n    \"\"\"\n    Run the PraisonAI application.\n    \"\"\"\n    self.main()\n</code></pre>"},{"location":"api/#praisonai.deploy.CloudDeployer","title":"<code>CloudDeployer</code>","text":"<p>A class for deploying a cloud-based application.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Loads environment variables from .env file or system and sets them.</p> Source code in <code>praisonai/deploy.py</code> <pre><code>class CloudDeployer:\n    \"\"\"\n    A class for deploying a cloud-based application.\n\n    Attributes:\n        None\n\n    Methods:\n        __init__(self):\n            Loads environment variables from .env file or system and sets them.\n\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Loads environment variables from .env file or system and sets them.\n\n        Parameters:\n            self: An instance of the CloudDeployer class.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        # Load environment variables from .env file or system\n        load_dotenv()\n        self.set_environment_variables()\n\n    def create_dockerfile(self):\n        \"\"\"\n        Creates a Dockerfile for the application.\n\n        Parameters:\n            self: An instance of the CloudDeployer class.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        This method creates a Dockerfile in the current directory with the specified content.\n        The Dockerfile is used to build a Docker image for the application.\n        The content of the Dockerfile includes instructions to use the Python 3.11-slim base image,\n        set the working directory to /app, copy the current directory contents into the container,\n        install the required Python packages (flask, praisonai, gunicorn, and markdown),\n        expose port 8080, and run the application using Gunicorn.\n        \"\"\"\n        with open(\"Dockerfile\", \"w\") as file:\n            file.write(\"FROM python:3.11-slim\\n\")\n            file.write(\"WORKDIR /app\\n\")\n            file.write(\"COPY . .\\n\")\n            file.write(\"RUN pip install flask praisonai==0.0.50 gunicorn markdown\\n\")\n            file.write(\"EXPOSE 8080\\n\")\n            file.write('CMD [\"gunicorn\", \"-b\", \"0.0.0.0:8080\", \"api:app\"]\\n')\n\n    def create_api_file(self):\n        \"\"\"\n        Creates an API file for the application.\n\n        Parameters:\n            self (CloudDeployer): An instance of the CloudDeployer class.\n\n        Returns:\n            None\n\n        This method creates an API file named \"api.py\" in the current directory. The file contains a basic Flask application that uses the PraisonAI library to run a simple agent and returns the output as an HTML page. The application listens on the root path (\"/\") and uses the Markdown library to format the output.\n        \"\"\"\n        with open(\"api.py\", \"w\") as file:\n            file.write(\"from flask import Flask\\n\")\n            file.write(\"from praisonai import PraisonAI\\n\")\n            file.write(\"import markdown\\n\\n\")\n            file.write(\"app = Flask(__name__)\\n\\n\")\n            file.write(\"def basic():\\n\")\n            file.write(\"    praisonai = PraisonAI(agent_file=\\\"agents.yaml\\\")\\n\")\n            file.write(\"    return praisonai.run()\\n\\n\")\n            file.write(\"@app.route('/')\\n\")\n            file.write(\"def home():\\n\")\n            file.write(\"    output = basic()\\n\")\n            file.write(\"    html_output = markdown.markdown(output)\\n\")\n            file.write(\"    return f'&lt;html&gt;&lt;body&gt;{html_output}&lt;/body&gt;&lt;/html&gt;'\\n\\n\")\n            file.write(\"if __name__ == \\\"__main__\\\":\\n\")\n            file.write(\"    app.run(debug=True)\\n\")\n\n    def set_environment_variables(self):\n        \"\"\"Sets environment variables with fallback to .env values or defaults.\"\"\"\n        os.environ[\"OPENAI_MODEL_NAME\"] = os.getenv(\"OPENAI_MODEL_NAME\", \"gpt-4o\")\n        os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"Enter your API key\")\n        os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n\n    def run_commands(self):\n        \"\"\"\n        Sets environment variables with fallback to .env values or defaults.\n\n        Parameters:\n            None\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        This method sets environment variables for the application. It uses the `os.environ` dictionary to set the following environment variables:\n\n        - `OPENAI_MODEL_NAME`: The name of the OpenAI model to use. If not specified in the .env file, it defaults to \"gpt-4o\".\n        - `OPENAI_API_KEY`: The API key for accessing the OpenAI API. If not specified in the .env file, it defaults to \"Enter your API key\".\n        - `OPENAI_API_BASE`: The base URL for the OpenAI API. If not specified in the .env file, it defaults to \"https://api.openai.com/v1\".\n        \"\"\"\n        self.create_api_file()\n        self.create_dockerfile()\n        \"\"\"Runs a sequence of shell commands for deployment, continues on error.\"\"\"\n        commands = [\n            \"yes | gcloud auth configure-docker us-central1-docker.pkg.dev\",\n            \"gcloud artifacts repositories create praisonai-repository --repository-format=docker --location=us-central1\",\n            \"docker build --platform linux/amd64 -t gcr.io/$(gcloud config get-value project)/praisonai-app:latest .\",\n            \"docker tag gcr.io/$(gcloud config get-value project)/praisonai-app:latest us-central1-docker.pkg.dev/$(gcloud config get-value project)/praisonai-repository/praisonai-app:latest\",\n            \"docker push us-central1-docker.pkg.dev/$(gcloud config get-value project)/praisonai-repository/praisonai-app:latest\",\n            \"gcloud run deploy praisonai-service --image us-central1-docker.pkg.dev/$(gcloud config get-value project)/praisonai-repository/praisonai-app:latest --platform managed --region us-central1 --allow-unauthenticated --set-env-vars OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME},OPENAI_API_KEY=${OPENAI_API_KEY},OPENAI_API_BASE=${OPENAI_API_BASE}\"\n        ]\n\n        for cmd in commands:\n            try:\n                subprocess.run(cmd, shell=True, check=True)\n            except subprocess.CalledProcessError as e:\n                print(f\"ERROR: Command '{e.cmd}' failed with exit status {e.returncode}\")\n                print(f\"Continuing with the next command...\")\n</code></pre>"},{"location":"api/#praisonai.deploy.CloudDeployer.__init__","title":"<code>__init__()</code>","text":"<p>Loads environment variables from .env file or system and sets them.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <p>An instance of the CloudDeployer class.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>praisonai/deploy.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Loads environment variables from .env file or system and sets them.\n\n    Parameters:\n        self: An instance of the CloudDeployer class.\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    \"\"\"\n    # Load environment variables from .env file or system\n    load_dotenv()\n    self.set_environment_variables()\n</code></pre>"},{"location":"api/#praisonai.deploy.CloudDeployer.create_api_file","title":"<code>create_api_file()</code>","text":"<p>Creates an API file for the application.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>CloudDeployer</code> <p>An instance of the CloudDeployer class.</p> required <p>Returns:</p> Type Description <p>None</p> <p>This method creates an API file named \"api.py\" in the current directory. The file contains a basic Flask application that uses the PraisonAI library to run a simple agent and returns the output as an HTML page. The application listens on the root path (\"/\") and uses the Markdown library to format the output.</p> Source code in <code>praisonai/deploy.py</code> <pre><code>def create_api_file(self):\n    \"\"\"\n    Creates an API file for the application.\n\n    Parameters:\n        self (CloudDeployer): An instance of the CloudDeployer class.\n\n    Returns:\n        None\n\n    This method creates an API file named \"api.py\" in the current directory. The file contains a basic Flask application that uses the PraisonAI library to run a simple agent and returns the output as an HTML page. The application listens on the root path (\"/\") and uses the Markdown library to format the output.\n    \"\"\"\n    with open(\"api.py\", \"w\") as file:\n        file.write(\"from flask import Flask\\n\")\n        file.write(\"from praisonai import PraisonAI\\n\")\n        file.write(\"import markdown\\n\\n\")\n        file.write(\"app = Flask(__name__)\\n\\n\")\n        file.write(\"def basic():\\n\")\n        file.write(\"    praisonai = PraisonAI(agent_file=\\\"agents.yaml\\\")\\n\")\n        file.write(\"    return praisonai.run()\\n\\n\")\n        file.write(\"@app.route('/')\\n\")\n        file.write(\"def home():\\n\")\n        file.write(\"    output = basic()\\n\")\n        file.write(\"    html_output = markdown.markdown(output)\\n\")\n        file.write(\"    return f'&lt;html&gt;&lt;body&gt;{html_output}&lt;/body&gt;&lt;/html&gt;'\\n\\n\")\n        file.write(\"if __name__ == \\\"__main__\\\":\\n\")\n        file.write(\"    app.run(debug=True)\\n\")\n</code></pre>"},{"location":"api/#praisonai.deploy.CloudDeployer.create_dockerfile","title":"<code>create_dockerfile()</code>","text":"<p>Creates a Dockerfile for the application.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <p>An instance of the CloudDeployer class.</p> required <p>Returns:</p> Type Description <p>None</p> <p>This method creates a Dockerfile in the current directory with the specified content. The Dockerfile is used to build a Docker image for the application. The content of the Dockerfile includes instructions to use the Python 3.11-slim base image, set the working directory to /app, copy the current directory contents into the container, install the required Python packages (flask, praisonai, gunicorn, and markdown), expose port 8080, and run the application using Gunicorn.</p> Source code in <code>praisonai/deploy.py</code> <pre><code>def create_dockerfile(self):\n    \"\"\"\n    Creates a Dockerfile for the application.\n\n    Parameters:\n        self: An instance of the CloudDeployer class.\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    This method creates a Dockerfile in the current directory with the specified content.\n    The Dockerfile is used to build a Docker image for the application.\n    The content of the Dockerfile includes instructions to use the Python 3.11-slim base image,\n    set the working directory to /app, copy the current directory contents into the container,\n    install the required Python packages (flask, praisonai, gunicorn, and markdown),\n    expose port 8080, and run the application using Gunicorn.\n    \"\"\"\n    with open(\"Dockerfile\", \"w\") as file:\n        file.write(\"FROM python:3.11-slim\\n\")\n        file.write(\"WORKDIR /app\\n\")\n        file.write(\"COPY . .\\n\")\n        file.write(\"RUN pip install flask praisonai==0.0.50 gunicorn markdown\\n\")\n        file.write(\"EXPOSE 8080\\n\")\n        file.write('CMD [\"gunicorn\", \"-b\", \"0.0.0.0:8080\", \"api:app\"]\\n')\n</code></pre>"},{"location":"api/#praisonai.deploy.CloudDeployer.run_commands","title":"<code>run_commands()</code>","text":"<p>Sets environment variables with fallback to .env values or defaults.</p> <p>Returns:</p> Type Description <p>None</p> <p>This method sets environment variables for the application. It uses the <code>os.environ</code> dictionary to set the following environment variables:</p> <ul> <li><code>OPENAI_MODEL_NAME</code>: The name of the OpenAI model to use. If not specified in the .env file, it defaults to \"gpt-4o\".</li> <li><code>OPENAI_API_KEY</code>: The API key for accessing the OpenAI API. If not specified in the .env file, it defaults to \"Enter your API key\".</li> <li><code>OPENAI_API_BASE</code>: The base URL for the OpenAI API. If not specified in the .env file, it defaults to \"https://api.openai.com/v1\".</li> </ul> Source code in <code>praisonai/deploy.py</code> <pre><code>def run_commands(self):\n    \"\"\"\n    Sets environment variables with fallback to .env values or defaults.\n\n    Parameters:\n        None\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    This method sets environment variables for the application. It uses the `os.environ` dictionary to set the following environment variables:\n\n    - `OPENAI_MODEL_NAME`: The name of the OpenAI model to use. If not specified in the .env file, it defaults to \"gpt-4o\".\n    - `OPENAI_API_KEY`: The API key for accessing the OpenAI API. If not specified in the .env file, it defaults to \"Enter your API key\".\n    - `OPENAI_API_BASE`: The base URL for the OpenAI API. If not specified in the .env file, it defaults to \"https://api.openai.com/v1\".\n    \"\"\"\n    self.create_api_file()\n    self.create_dockerfile()\n    \"\"\"Runs a sequence of shell commands for deployment, continues on error.\"\"\"\n    commands = [\n        \"yes | gcloud auth configure-docker us-central1-docker.pkg.dev\",\n        \"gcloud artifacts repositories create praisonai-repository --repository-format=docker --location=us-central1\",\n        \"docker build --platform linux/amd64 -t gcr.io/$(gcloud config get-value project)/praisonai-app:latest .\",\n        \"docker tag gcr.io/$(gcloud config get-value project)/praisonai-app:latest us-central1-docker.pkg.dev/$(gcloud config get-value project)/praisonai-repository/praisonai-app:latest\",\n        \"docker push us-central1-docker.pkg.dev/$(gcloud config get-value project)/praisonai-repository/praisonai-app:latest\",\n        \"gcloud run deploy praisonai-service --image us-central1-docker.pkg.dev/$(gcloud config get-value project)/praisonai-repository/praisonai-app:latest --platform managed --region us-central1 --allow-unauthenticated --set-env-vars OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME},OPENAI_API_KEY=${OPENAI_API_KEY},OPENAI_API_BASE=${OPENAI_API_BASE}\"\n    ]\n\n    for cmd in commands:\n        try:\n            subprocess.run(cmd, shell=True, check=True)\n        except subprocess.CalledProcessError as e:\n            print(f\"ERROR: Command '{e.cmd}' failed with exit status {e.returncode}\")\n            print(f\"Continuing with the next command...\")\n</code></pre>"},{"location":"api/#praisonai.deploy.CloudDeployer.set_environment_variables","title":"<code>set_environment_variables()</code>","text":"<p>Sets environment variables with fallback to .env values or defaults.</p> Source code in <code>praisonai/deploy.py</code> <pre><code>def set_environment_variables(self):\n    \"\"\"Sets environment variables with fallback to .env values or defaults.\"\"\"\n    os.environ[\"OPENAI_MODEL_NAME\"] = os.getenv(\"OPENAI_MODEL_NAME\", \"gpt-4o\")\n    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"Enter your API key\")\n    os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n</code></pre>"},{"location":"auto/","title":"Auto","text":""},{"location":"auto/#full-automatic-mode","title":"Full Automatic Mode","text":"<pre><code>praisonai --auto create a movie script about Dog in Moon\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<ul> <li>Fork on GitHub: Use the \"Fork\" button on the repository page.</li> <li>Clone your fork: <code>git clone https://github.com/yourusername/praisonAI.git</code></li> <li>Create a branch: <code>git checkout -b new-feature</code></li> <li>Make changes and commit: <code>git commit -am \"Add some feature\"</code></li> <li>Push to your fork: <code>git push origin new-feature</code></li> <li>Submit a pull request via GitHub's web interface.</li> <li>Await feedback from project maintainers.</li> </ul>"},{"location":"deploy/","title":"Deploy","text":""},{"location":"deploy/#google-cloud","title":"Google Cloud","text":"<pre><code>gcloud init\ngcloud services enable run.googleapis.com\ngcloud services enable containerregistry.googleapis.com\ngcloud services enable cloudbuild.googleapis.com\n\nexport OPENAI_MODEL_NAME=\"gpt-4o\"\nexport OPENAI_API_KEY=\"Enter your API key\"\nexport OPENAI_API_BASE=\"https://api.openai.com/v1\"\n\nyes | gcloud auth configure-docker us-central1-docker.pkg.dev \ngcloud artifacts repositories create praisonai-repository --repository-format=docker --location=us-central1\n\nPROJECT_ID=$(gcloud config get-value project)\nTAG=\"latest\"\ndocker build --platform linux/amd64 -t gcr.io/${PROJECT_ID}/praisonai-app:${TAG} .\ndocker tag gcr.io/${PROJECT_ID}/praisonai-app:${TAG} us-central1-docker.pkg.dev/${PROJECT_ID}/praisonai-repository/praisonai-app:${TAG}\ndocker push us-central1-docker.pkg.dev/${PROJECT_ID}/praisonai-repository/praisonai-app:${TAG}\n\ngcloud run deploy praisonai-service \\\n    --image us-central1-docker.pkg.dev/${PROJECT_ID}/praisonai-repository/praisonai-app:${TAG} \\\n    --platform managed \\\n    --region us-central1 \\\n    --allow-unauthenticated \\\n    --set-env-vars OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME},OPENAI_API_KEY=${OPENAI_API_KEY},OPENAI_API_BASE=${OPENAI_API_BASE}\n</code></pre>"},{"location":"firecrawl/","title":"Firecrawl PraisonAI Integration","text":""},{"location":"firecrawl/#firecrawl-running-in-localhost3002","title":"Firecrawl running in Localhost:3002","text":"<pre><code>from firecrawl import FirecrawlApp\nfrom praisonai_tools import BaseTool\nimport re\n\nclass WebPageScraperTool(BaseTool):\n    name: str = \"Web Page Scraper Tool\"\n    description: str = \"Scrape and extract information from a given web page URL.\"\n\n    def _run(self, url: str) -&gt; str:\n        app = FirecrawlApp(api_url='http://localhost:3002')\n        response = app.scrape_url(url=url)\n        content = response[\"content\"]\n        # Remove all content above the line \"========================================================\"\n        if \"========================================================\" in content:\n            content = content.split(\"========================================================\", 1)[1]\n\n        # Remove all menu items and similar patterns\n        content = re.sub(r'\\*\\s+\\[.*?\\]\\(.*?\\)', '', content)\n        content = re.sub(r'\\[Skip to the content\\]\\(.*?\\)', '', content)\n        content = re.sub(r'\\[.*?\\]\\(.*?\\)', '', content)\n        content = re.sub(r'\\s*Menu\\s*', '', content)\n        content = re.sub(r'\\s*Search\\s*', '', content)\n        content = re.sub(r'Categories\\s*', '', content)\n\n        # Remove all URLs\n        content = re.sub(r'http\\S+', '', content)\n\n        # Remove empty lines or lines with only whitespace\n        content = '\\n'.join([line for line in content.split('\\n') if line.strip()])\n\n        # Limit to the first 1000 words\n        words = content.split()\n        if len(words) &gt; 1000:\n            content = ' '.join(words[:1000])\n\n        return content\n</code></pre>"},{"location":"home/","title":"Home","text":""},{"location":"home/#installation","title":"Installation","text":"<pre><code>pip install praisonai\n</code></pre>"},{"location":"home/#initialise","title":"Initialise","text":"<pre><code>export OPENAI_API_KEY=\"Enter your API key\"\n</code></pre> <p>Generate your OPENAI API KEY from here: https://platform.openai.com/api-keys</p> <p>Note: You can use other providers such as Ollama, Mistral ... etc. Details are provided at the bottom.</p> <p><pre><code>praisonai --init create a movie script about dog in moon\n</code></pre> This will automatically create agents.yaml file in the current directory.</p>"},{"location":"home/#to-initialse-with-a-specific-agent-framework-optional","title":"To initialse with a specific agent framework (Optional):","text":"<pre><code>praisonai --framework autogen --init create movie script about cat in mars\n</code></pre>"},{"location":"home/#run","title":"Run","text":"<pre><code>praisonai\n</code></pre> <p>or </p> <pre><code>python -m praisonai\n</code></pre>"},{"location":"home/#specify-the-agent-framework-optional","title":"Specify the agent framework (Optional):","text":"<pre><code>praisonai --framework autogen\n</code></pre>"},{"location":"home/#full-automatic-mode","title":"Full Automatic Mode","text":"<pre><code>praisonai --auto create a movie script about Dog in Moon\n</code></pre>"},{"location":"initialise/","title":"Initialise","text":"<pre><code>export OPENAI_API_KEY=\"Enter your API key\"\n</code></pre> <p>Generate your OPENAI API KEY from here: https://platform.openai.com/api-keys</p> <p>Note: You can use other providers such as Ollama, Mistral ... etc. Details are provided at the bottom.</p> <p><pre><code>praisonai --init create a movie script about dog in moon\n</code></pre> This will automatically create agents.yaml file in the current directory.</p>"},{"location":"installation/","title":"Installation","text":"<pre><code>pip install praisonai\n</code></pre>"},{"location":"models/","title":"Models in PraisonAI","text":"<ul> <li>OpenAI</li> <li>Groq</li> <li>Google Gemini</li> <li>Anthropic Claude</li> <li>Cohere</li> <li>Mistral</li> <li>Ollama</li> <li>Other Models</li> </ul>"},{"location":"models/#example-agentsyaml","title":"Example agents.yaml","text":"<p>This uses Multi-Agents with Multi-LLMs.</p> <pre><code>framework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    llm:  \n      model: \"groq/llama3-70b-8192\"\n    function_calling_llm: \n      model: \"google/gemini-1.5-flash-001\"\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung\n          diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - 'InternetSearchTool'\n  medical_writer:\n    backstory: Skilled in translating complex medical information into accessible\n      content.\n    goal: Compile comprehensive content on lung disease causes\n    role: Medical Writer\n    llm:  \n      model: \"anthropic/claude-3-haiku-20240307\"\n    function_calling_llm: \n      model: \"openai/gpt-4o\"\n    tasks:\n      content_creation:\n        description: Create detailed content summarizing the research findings on\n          lung disease causes.\n        expected_output: Document outlining various causes and risk factors of lung\n          diseases.\n    tools:\n    - ''\n  editor:\n    backstory: Proficient in editing medical content for accuracy and clarity.\n    goal: Review and refine content on lung disease causes\n    role: Editor\n    llm:  \n      model: \"cohere/command-r\"\n    tasks:\n      content_review:\n        description: Edit and refine the compiled content on lung disease causes for\n          accuracy and coherence.\n        expected_output: Finalized document on lung disease causes ready for dissemination.\n    tools:\n    - ''\ndependencies: []\n</code></pre>"},{"location":"run/","title":"Run","text":"<pre><code>praisonai\n</code></pre> <p>or </p> <pre><code>python -m praisonai\n</code></pre>"},{"location":"run/#specify-the-agent-framework-optional","title":"Specify the agent framework (Optional):","text":"<pre><code>praisonai --framework autogen\n</code></pre>"},{"location":"run/#full-automatic-mode","title":"Full Automatic Mode","text":"<pre><code>praisonai --auto create a movie script about Dog in Moon\n</code></pre>"},{"location":"tldr/","title":"TL;DR","text":""},{"location":"tldr/#run-throught-terminal","title":"Run throught Terminal","text":"<pre><code>pip install praisonai\nexport OPENAI_API_KEY=\"Enter your API key\"\npraisonai --init create a movie script about dog in moon\npraisonai\n</code></pre>"},{"location":"tldr/#user-interface","title":"User Interface","text":"<pre><code>pip install -U \"praisonai[ui]\"\nexport OPENAI_API_KEY=\"Enter your API key\"\nchainlit create-secret\nexport CHAINLIT_AUTH_SECRET=xxxxxxxx\npraisonai ui\n</code></pre>"},{"location":"tools/","title":"Tools","text":""},{"location":"tools/#inbuild-tools","title":"Inbuild Tools","text":"<ul> <li>CodeDocsSearchTool</li> <li>CSVSearchTool</li> <li>DirectorySearchTool</li> <li>DirectoryReadTool</li> <li>DOCXSearchTool</li> <li>FileReadTool</li> <li>GithubSearchTool</li> <li>SerperDevTool</li> <li>TXTSearchTool</li> <li>JSONSearchTool</li> <li>MDXSearchTool</li> <li>PDFSearchTool</li> <li>PGSearchTool</li> <li>RagTool</li> <li>ScrapeElementFromWebsiteTool</li> <li>ScrapeWebsiteTool</li> <li>SeleniumScrapingTool</li> <li>WebsiteSearchTool</li> <li>XMLSearchTool</li> <li>YoutubeChannelSearchTool</li> <li>YoutubeVideoSearchTool</li> </ul>"},{"location":"tools/#example-usage","title":"Example Usage","text":"<pre><code>framework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - WebsiteSearchTool\n</code></pre>"},{"location":"developers/agents-playbook/","title":"Agents Playbook","text":""},{"location":"developers/agents-playbook/#simple-playbook-example","title":"Simple Playbook Example","text":"<pre><code>framework: crewai\ntopic: Artificial Intelligence\nroles:\n  screenwriter:\n    backstory: 'Skilled in crafting scripts with engaging dialogue about {topic}.'\n    goal: Create scripts from concepts.\n    role: Screenwriter\n    tasks:\n      scriptwriting_task:\n        description: 'Develop scripts with compelling characters and dialogue about {topic}.'\n        expected_output: 'Complete script ready for production.'\n</code></pre>"},{"location":"developers/agents-playbook/#detailed-playbook-example","title":"Detailed Playbook Example","text":"<pre><code>framework: crewai\ntopic: Artificial Intelligence\nroles:\n  movie_concept_creator:\n    backstory: 'Creative thinker with a deep understanding of cinematic storytelling,\n      capable of using AI-generated storylines to create unique and compelling movie\n      ideas.'\n    goal: Generate engaging movie concepts using AI storylines\n    role: Movie Concept Creator\n    tasks:\n      movie_concept_development:\n        description: 'Develop movie concepts from AI-generated storylines, ensuring\n          they are engaging and have strong narrative arcs.'\n        expected_output: 'Well-structured movie concept document with character\n          bios, settings, and plot outlines.'\n  screenwriter:\n    backstory: 'Expert in writing engaging dialogue and script structure, able to\n      turn movie concepts into production-ready scripts.'\n    goal: Write compelling scripts based on movie concepts\n    role: Screenwriter\n    tasks:\n      scriptwriting_task:\n        description: 'Turn movie concepts into polished scripts with well-developed\n          characters, strong dialogue, and effective scene transitions.'\n        expected_output: 'Production-ready script with a beginning, middle, and\n          end, along with character development and engaging dialogues.'\n  editor:\n    backstory: 'Adept at identifying inconsistencies, improving language usage,\n      and maintaining the overall flow of the script.'\n    goal: Refine the scripts and ensure continuity of the movie storyline\n    role: Editor\n    tasks:\n      editing_task:\n        description: 'Review, edit, and refine the scripts to ensure they are cohesive\n          and follow a well-structured narrative.'\n        expected_output: 'A polished final draft of the script with no inconsistencies,\n          strong character development, and effective dialogue.'\ndependencies: []\n</code></pre>"},{"location":"developers/googlecolab-tools/","title":"Google Colab Tools","text":"<pre><code>!pip install -Uq praisonai duckduckgo_search\n</code></pre> <pre><code>from duckduckgo_search import DDGS\nfrom praisonai_tools import BaseTool\n\nclass InternetSearchTool(BaseTool):\n    name: str = \"InternetSearchTool\"\n    description: str = \"Search Internet for relevant information based on a query or latest news\"\n\n    def _run(self, query: str):\n        ddgs = DDGS()\n        results = ddgs.text(keywords=query, region='wt-wt', safesearch='moderate', max_results=5)\n        return results\n</code></pre> <pre><code>import os\nimport yaml\nfrom praisonai import PraisonAI\nfrom google.colab import userdata\n\n# Example agent_yaml content\nagent_yaml = \"\"\"\nframework: \"crewai\"\ntopic: \"Space Exploration\"\n\nroles:\n  astronomer:\n    role: \"Space Researcher\"\n    goal: \"Discover new insights about {topic}\"\n    backstory: \"You are a curious and dedicated astronomer with a passion for unraveling the mysteries of the cosmos.\"\n    tasks:\n      investigate_exoplanets:\n        description: \"Research and compile information about exoplanets discovered in the last decade.\"\n        expected_output: \"A summarized report on exoplanet discoveries, including their size, potential habitability, and distance from Earth.\"\n    tools:\n      - \"InternetSearchTool\"\n\"\"\"\n\n# Create a PraisonAI instance with the agent_yaml content\npraisonai = PraisonAI(agent_yaml=agent_yaml)\n\n# Add OPENAI_API_KEY Secrets to Google Colab on the Left Hand Side \ud83d\udd11 or Enter Manually Below\nos.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY') or \"ENTER OPENAI_API_KEY HERE\"\n\n# Run PraisonAI\nresult = praisonai.run()\n\n# Print the result\nprint(result)\n</code></pre> <pre><code> [2024-07-03 04:53:48][DEBUG]: == Working Agent: Space Researcher\n [2024-07-03 04:53:48][INFO]: == Starting Task: Research and compile information about exoplanets discovered in the last decade.\n\n\n&gt; Entering new CrewAgentExecutor chain...\nI now can give a great answer.\n\nFinal Answer:\n\nOver the last decade, the field of exoplanet research has experienced significant advancements, leading to the discovery of thousands of exoplanets. These discoveries have been made possible through missions like NASA's Kepler and TESS (Transiting Exoplanet Survey Satellite), as well as ground-based observatories. Here is a summarized report on some of the notable exoplanet discoveries, including their size, potential habitability, and distance from Earth:\n\n1. **Kepler-452b**\n   - **Size**: Approximately 1.6 times the radius of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, where liquid water could exist. It is often referred to as Earth's \"cousin.\"\n   - **Distance from Earth**: About 1,400 light-years\n\n2. **Proxima Centauri b**\n   - **Size**: About 1.17 times the mass of Earth\n   - **Potential Habitability**: Located in the habitable zone of Proxima Centauri, the closest star to the Sun. It has the potential to have liquid water.\n   - **Distance from Earth**: 4.24 light-years\n\n3. **TRAPPIST-1 System**\n   - **Size**: The system includes seven Earth-sized planets\n   - **Potential Habitability**: Three of the planets (TRAPPIST-1e, TRAPPIST-1f, and TRAPPIST-1g) are located in the habitable zone and could potentially support liquid water.\n   - **Distance from Earth**: Approximately 39 light-years\n\n4. **LHS 1140b**\n   - **Size**: About 1.4 times the size of Earth and 6.6 times its mass\n   - **Potential Habitability**: Located in the habitable zone of its star. It has a thick atmosphere and conditions that could support life.\n   - **Distance from Earth**: About 40 light-years\n\n5. **Kepler-186f**\n   - **Size**: Similar to Earth in size\n   - **Potential Habitability**: The first Earth-sized planet discovered in the habitable zone of another star. It has potential for liquid water on its surface.\n   - **Distance from Earth**: About 500 light-years\n\n6. **K2-18b**\n   - **Size**: Approximately 2.6 times the radius of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, with evidence of water vapor in its atmosphere.\n   - **Distance from Earth**: About 124 light-years\n\n7. **GJ 357 d**\n   - **Size**: About 6.1 times the mass of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, with the potential to have liquid water on its surface.\n   - **Distance from Earth**: About 31 light-years\n\nThese discoveries highlight the diversity of exoplanets in terms of size, composition, and potential habitability. The search for exoplanets is crucial for understanding the potential for life beyond Earth and the formation and evolution of planetary systems. Ongoing and future missions, such as the James Webb Space Telescope, are expected to provide even more detailed information about these distant worlds.\n\nThe continuous exploration and study of exoplanets will undoubtedly lead to new insights and perhaps even the discovery of life beyond our solar system.\n\n\n\n&gt; Finished chain.\n [2024-07-03 04:53:58][DEBUG]: == [Space Researcher] Task output: Over the last decade, the field of exoplanet research has experienced significant advancements, leading to the discovery of thousands of exoplanets. These discoveries have been made possible through missions like NASA's Kepler and TESS (Transiting Exoplanet Survey Satellite), as well as ground-based observatories. Here is a summarized report on some of the notable exoplanet discoveries, including their size, potential habitability, and distance from Earth:\n\n1. **Kepler-452b**\n   - **Size**: Approximately 1.6 times the radius of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, where liquid water could exist. It is often referred to as Earth's \"cousin.\"\n   - **Distance from Earth**: About 1,400 light-years\n\n2. **Proxima Centauri b**\n   - **Size**: About 1.17 times the mass of Earth\n   - **Potential Habitability**: Located in the habitable zone of Proxima Centauri, the closest star to the Sun. It has the potential to have liquid water.\n   - **Distance from Earth**: 4.24 light-years\n\n3. **TRAPPIST-1 System**\n   - **Size**: The system includes seven Earth-sized planets\n   - **Potential Habitability**: Three of the planets (TRAPPIST-1e, TRAPPIST-1f, and TRAPPIST-1g) are located in the habitable zone and could potentially support liquid water.\n   - **Distance from Earth**: Approximately 39 light-years\n\n4. **LHS 1140b**\n   - **Size**: About 1.4 times the size of Earth and 6.6 times its mass\n   - **Potential Habitability**: Located in the habitable zone of its star. It has a thick atmosphere and conditions that could support life.\n   - **Distance from Earth**: About 40 light-years\n\n5. **Kepler-186f**\n   - **Size**: Similar to Earth in size\n   - **Potential Habitability**: The first Earth-sized planet discovered in the habitable zone of another star. It has potential for liquid water on its surface.\n   - **Distance from Earth**: About 500 light-years\n\n6. **K2-18b**\n   - **Size**: Approximately 2.6 times the radius of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, with evidence of water vapor in its atmosphere.\n   - **Distance from Earth**: About 124 light-years\n\n7. **GJ 357 d**\n   - **Size**: About 6.1 times the mass of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, with the potential to have liquid water on its surface.\n   - **Distance from Earth**: About 31 light-years\n\nThese discoveries highlight the diversity of exoplanets in terms of size, composition, and potential habitability. The search for exoplanets is crucial for understanding the potential for life beyond Earth and the formation and evolution of planetary systems. Ongoing and future missions, such as the James Webb Space Telescope, are expected to provide even more detailed information about these distant worlds.\n\nThe continuous exploration and study of exoplanets will undoubtedly lead to new insights and perhaps even the discovery of life beyond our solar system.\n\n\n### Task Output ###\nOver the last decade, the field of exoplanet research has experienced significant advancements, leading to the discovery of thousands of exoplanets. These discoveries have been made possible through missions like NASA's Kepler and TESS (Transiting Exoplanet Survey Satellite), as well as ground-based observatories. Here is a summarized report on some of the notable exoplanet discoveries, including their size, potential habitability, and distance from Earth:\n\n1. **Kepler-452b**\n   - **Size**: Approximately 1.6 times the radius of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, where liquid water could exist. It is often referred to as Earth's \"cousin.\"\n   - **Distance from Earth**: About 1,400 light-years\n\n2. **Proxima Centauri b**\n   - **Size**: About 1.17 times the mass of Earth\n   - **Potential Habitability**: Located in the habitable zone of Proxima Centauri, the closest star to the Sun. It has the potential to have liquid water.\n   - **Distance from Earth**: 4.24 light-years\n\n3. **TRAPPIST-1 System**\n   - **Size**: The system includes seven Earth-sized planets\n   - **Potential Habitability**: Three of the planets (TRAPPIST-1e, TRAPPIST-1f, and TRAPPIST-1g) are located in the habitable zone and could potentially support liquid water.\n   - **Distance from Earth**: Approximately 39 light-years\n\n4. **LHS 1140b**\n   - **Size**: About 1.4 times the size of Earth and 6.6 times its mass\n   - **Potential Habitability**: Located in the habitable zone of its star. It has a thick atmosphere and conditions that could support life.\n   - **Distance from Earth**: About 40 light-years\n\n5. **Kepler-186f**\n   - **Size**: Similar to Earth in size\n   - **Potential Habitability**: The first Earth-sized planet discovered in the habitable zone of another star. It has potential for liquid water on its surface.\n   - **Distance from Earth**: About 500 light-years\n\n6. **K2-18b**\n   - **Size**: Approximately 2.6 times the radius of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, with evidence of water vapor in its atmosphere.\n   - **Distance from Earth**: About 124 light-years\n\n7. **GJ 357 d**\n   - **Size**: About 6.1 times the mass of Earth\n   - **Potential Habitability**: Located in the habitable zone of its star, with the potential to have liquid water on its surface.\n   - **Distance from Earth**: About 31 light-years\n\nThese discoveries highlight the diversity of exoplanets in terms of size, composition, and potential habitability. The search for exoplanets is crucial for understanding the potential for life beyond Earth and the formation and evolution of planetary systems. Ongoing and future missions, such as the James Webb Space Telescope, are expected to provide even more detailed information about these distant worlds.\n\nThe continuous exploration and study of exoplanets will undoubtedly lead to new insights and perhaps even the discovery of life beyond our solar system.\n</code></pre> <p>::: :::</p>"},{"location":"developers/googlecolab/","title":"Google Colab","text":"<pre><code>!pip install -Uq praisonai\n</code></pre> <pre><code>import os\nimport yaml\nfrom praisonai import PraisonAI\nfrom google.colab import userdata\n\n# Example agent_yaml content\nagent_yaml = \"\"\"\nframework: \"crewai\"\ntopic: \"Space Exploration\"\n\nroles:\n  astronomer:\n    role: \"Space Researcher\"\n    goal: \"Discover new insights about {topic}\"\n    backstory: \"You are a curious and dedicated astronomer with a passion for unraveling the mysteries of the cosmos.\"\n    tasks:\n      investigate_exoplanets:\n        description: \"Research and compile information about exoplanets discovered in the last decade.\"\n        expected_output: \"A summarized report on exoplanet discoveries, including their size, potential habitability, and distance from Earth.\"\n\"\"\"\n\n# Create a PraisonAI instance with the agent_yaml content\npraisonai = PraisonAI(agent_yaml=agent_yaml)\n\n# Add OPENAI_API_KEY Secrets to Google Colab on the Left Hand Side \ud83d\udd11 or Enter Manually Below\nos.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY') or \"ENTER OPENAI_API_KEY HERE\"\n\n# Run PraisonAI\nresult = praisonai.run()\n\n# Print the result\nprint(result)\n</code></pre> <pre><code> [2024-07-03 04:39:09][DEBUG]: == Working Agent: Space Researcher\n [2024-07-03 04:39:09][INFO]: == Starting Task: Research and compile information about exoplanets discovered in the last decade.\n\n\n&gt; Entering new CrewAgentExecutor chain...\nI now can give a great answer.\n\nFinal Answer:\n\nIn the last decade, the field of exoplanet research has experienced a remarkable surge in discoveries, thanks to advancements in technology and dedicated space missions such as Kepler, TESS (Transiting Exoplanet Survey Satellite), and various ground-based observatories. Here is a summarized report on some of the notable exoplanet discoveries, highlighting their size, potential habitability, and distance from Earth:\n\n1. **Kepler-452b**\n   - **Size:** Approximately 60% larger in diameter than Earth.\n   - **Potential Habitability:** Often referred to as \"Earth's Cousin,\" Kepler-452b orbits within the habitable zone of its star, where liquid water could exist. The planet receives a similar amount of energy from its star as Earth does from the Sun.\n   - **Distance from Earth:** About 1,402 light-years.\n\n2. **Proxima Centauri b**\n   - **Size:** Slightly larger than Earth, with a minimum mass of 1.17 Earth masses.\n   - **Potential Habitability:** Located in the habitable zone of Proxima Centauri, the closest known star to the Sun. Potential for liquid water exists, but its habitability is uncertain due to stellar flare activity.\n   - **Distance from Earth:** 4.24 light-years.\n\n3. **TRAPPIST-1 System**\n   - **Size:** The system contains seven Earth-sized planets. TRAPPIST-1e, f, and g are within the star's habitable zone.\n   - **Potential Habitability:** TRAPPIST-1e is considered the most promising candidate for habitability, as it has a rocky composition and is located in the middle of the habitable zone.\n   - **Distance from Earth:** About 39 light-years.\n\n4. **LHS 1140 b**\n   - **Size:** About 1.4 times the size of Earth with a mass of around 6.6 Earth masses.\n   - **Potential Habitability:** Resides in the habitable zone of its red dwarf star. The planet is likely rocky and has an atmosphere that could support life.\n   - **Distance from Earth:** Approximately 40 light-years.\n\n5. **K2-18b**\n   - **Size:** About 2.6 times the size of Earth with a mass of 8.6 Earth masses.\n   - **Potential Habitability:** This exoplanet lies within the habitable zone and has been detected to have water vapor in its atmosphere. It is considered one of the most promising candidates for habitability outside our solar system.\n   - **Distance from Earth:** Roughly 124 light-years.\n\n6. **Gliese 667 Cc**\n   - **Size:** At least 4.5 times the mass of Earth.\n   - **Potential Habitability:** Orbits within the habitable zone of its host star, Gliese 667 C. Its orbit allows for the possibility of liquid water on its surface.\n   - **Distance from Earth:** About 23.62 light-years.\n\n7. **HD 40307 g**\n   - **Size:** A super-Earth with at least 7 Earth masses.\n   - **Potential Habitability:** Located in the habitable zone of its star, this planet could potentially support liquid water and therefore life.\n   - **Distance from Earth:** Approximately 42 light-years.\n\n8. **Ross 128 b**\n   - **Size:** Similar to Earth, with a minimum mass of 1.35 Earth masses.\n   - **Potential Habitability:** Orbits within the habitable zone of the relatively quiet red dwarf star Ross 128. The planet has mild temperatures that could allow for liquid water.\n   - **Distance from Earth:** About 11 light-years.\n\n9. **Teegarden's Star b**\n   - **Size:** Comparable to Earth.\n   - **Potential Habitability:** Orbits within the habitable zone of Teegarden's Star, a cool red dwarf. Conditions could be suitable for liquid water.\n   - **Distance from Earth:** Approximately 12 light-years.\n\n10. **Barnard's Star b**\n    - **Size:** A super-Earth with a mass of about 3.2 Earth masses.\n    - **Potential Habitability:** Located just outside the traditional habitable zone, but still within a range where liquid water could exist under certain conditions.\n    - **Distance from Earth:** About 6 light-years.\n\nThese discoveries highlight the diverse and intriguing nature of exoplanets found in the last decade. Each of these planets adds valuable information to our understanding of planetary formation, potential habitability, and the search for extraterrestrial life. Continued advancements in detection methods and technologies promise to further expand our knowledge in the years to come.\n\n&gt; Finished chain.\n [2024-07-03 04:39:25][DEBUG]: == [Space Researcher] Task output: In the last decade, the field of exoplanet research has experienced a remarkable surge in discoveries, thanks to advancements in technology and dedicated space missions such as Kepler, TESS (Transiting Exoplanet Survey Satellite), and various ground-based observatories. Here is a summarized report on some of the notable exoplanet discoveries, highlighting their size, potential habitability, and distance from Earth:\n\n1. **Kepler-452b**\n   - **Size:** Approximately 60% larger in diameter than Earth.\n   - **Potential Habitability:** Often referred to as \"Earth's Cousin,\" Kepler-452b orbits within the habitable zone of its star, where liquid water could exist. The planet receives a similar amount of energy from its star as Earth does from the Sun.\n   - **Distance from Earth:** About 1,402 light-years.\n\n2. **Proxima Centauri b**\n   - **Size:** Slightly larger than Earth, with a minimum mass of 1.17 Earth masses.\n   - **Potential Habitability:** Located in the habitable zone of Proxima Centauri, the closest known star to the Sun. Potential for liquid water exists, but its habitability is uncertain due to stellar flare activity.\n   - **Distance from Earth:** 4.24 light-years.\n\n3. **TRAPPIST-1 System**\n   - **Size:** The system contains seven Earth-sized planets. TRAPPIST-1e, f, and g are within the star's habitable zone.\n   - **Potential Habitability:** TRAPPIST-1e is considered the most promising candidate for habitability, as it has a rocky composition and is located in the middle of the habitable zone.\n   - **Distance from Earth:** About 39 light-years.\n\n4. **LHS 1140 b**\n   - **Size:** About 1.4 times the size of Earth with a mass of around 6.6 Earth masses.\n   - **Potential Habitability:** Resides in the habitable zone of its red dwarf star. The planet is likely rocky and has an atmosphere that could support life.\n   - **Distance from Earth:** Approximately 40 light-years.\n\n5. **K2-18b**\n   - **Size:** About 2.6 times the size of Earth with a mass of 8.6 Earth masses.\n   - **Potential Habitability:** This exoplanet lies within the habitable zone and has been detected to have water vapor in its atmosphere. It is considered one of the most promising candidates for habitability outside our solar system.\n   - **Distance from Earth:** Roughly 124 light-years.\n\n6. **Gliese 667 Cc**\n   - **Size:** At least 4.5 times the mass of Earth.\n   - **Potential Habitability:** Orbits within the habitable zone of its host star, Gliese 667 C. Its orbit allows for the possibility of liquid water on its surface.\n   - **Distance from Earth:** About 23.62 light-years.\n\n7. **HD 40307 g**\n   - **Size:** A super-Earth with at least 7 Earth masses.\n   - **Potential Habitability:** Located in the habitable zone of its star, this planet could potentially support liquid water and therefore life.\n   - **Distance from Earth:** Approximately 42 light-years.\n\n8. **Ross 128 b**\n   - **Size:** Similar to Earth, with a minimum mass of 1.35 Earth masses.\n   - **Potential Habitability:** Orbits within the habitable zone of the relatively quiet red dwarf star Ross 128. The planet has mild temperatures that could allow for liquid water.\n   - **Distance from Earth:** About 11 light-years.\n\n9. **Teegarden's Star b**\n   - **Size:** Comparable to Earth.\n   - **Potential Habitability:** Orbits within the habitable zone of Teegarden's Star, a cool red dwarf. Conditions could be suitable for liquid water.\n   - **Distance from Earth:** Approximately 12 light-years.\n\n10. **Barnard's Star b**\n    - **Size:** A super-Earth with a mass of about 3.2 Earth masses.\n    - **Potential Habitability:** Located just outside the traditional habitable zone, but still within a range where liquid water could exist under certain conditions.\n    - **Distance from Earth:** About 6 light-years.\n\nThese discoveries highlight the diverse and intriguing nature of exoplanets found in the last decade. Each of these planets adds valuable information to our understanding of planetary formation, potential habitability, and the search for extraterrestrial life. Continued advancements in detection methods and technologies promise to further expand our knowledge in the years to come.\n\n\n### Task Output ###\nIn the last decade, the field of exoplanet research has experienced a remarkable surge in discoveries, thanks to advancements in technology and dedicated space missions such as Kepler, TESS (Transiting Exoplanet Survey Satellite), and various ground-based observatories. Here is a summarized report on some of the notable exoplanet discoveries, highlighting their size, potential habitability, and distance from Earth:\n\n1. **Kepler-452b**\n   - **Size:** Approximately 60% larger in diameter than Earth.\n   - **Potential Habitability:** Often referred to as \"Earth's Cousin,\" Kepler-452b orbits within the habitable zone of its star, where liquid water could exist. The planet receives a similar amount of energy from its star as Earth does from the Sun.\n   - **Distance from Earth:** About 1,402 light-years.\n\n2. **Proxima Centauri b**\n   - **Size:** Slightly larger than Earth, with a minimum mass of 1.17 Earth masses.\n   - **Potential Habitability:** Located in the habitable zone of Proxima Centauri, the closest known star to the Sun. Potential for liquid water exists, but its habitability is uncertain due to stellar flare activity.\n   - **Distance from Earth:** 4.24 light-years.\n\n3. **TRAPPIST-1 System**\n   - **Size:** The system contains seven Earth-sized planets. TRAPPIST-1e, f, and g are within the star's habitable zone.\n   - **Potential Habitability:** TRAPPIST-1e is considered the most promising candidate for habitability, as it has a rocky composition and is located in the middle of the habitable zone.\n   - **Distance from Earth:** About 39 light-years.\n\n4. **LHS 1140 b**\n   - **Size:** About 1.4 times the size of Earth with a mass of around 6.6 Earth masses.\n   - **Potential Habitability:** Resides in the habitable zone of its red dwarf star. The planet is likely rocky and has an atmosphere that could support life.\n   - **Distance from Earth:** Approximately 40 light-years.\n\n5. **K2-18b**\n   - **Size:** About 2.6 times the size of Earth with a mass of 8.6 Earth masses.\n   - **Potential Habitability:** This exoplanet lies within the habitable zone and has been detected to have water vapor in its atmosphere. It is considered one of the most promising candidates for habitability outside our solar system.\n   - **Distance from Earth:** Roughly 124 light-years.\n\n6. **Gliese 667 Cc**\n   - **Size:** At least 4.5 times the mass of Earth.\n   - **Potential Habitability:** Orbits within the habitable zone of its host star, Gliese 667 C. Its orbit allows for the possibility of liquid water on its surface.\n   - **Distance from Earth:** About 23.62 light-years.\n\n7. **HD 40307 g**\n   - **Size:** A super-Earth with at least 7 Earth masses.\n   - **Potential Habitability:** Located in the habitable zone of its star, this planet could potentially support liquid water and therefore life.\n   - **Distance from Earth:** Approximately 42 light-years.\n\n8. **Ross 128 b**\n   - **Size:** Similar to Earth, with a minimum mass of 1.35 Earth masses.\n   - **Potential Habitability:** Orbits within the habitable zone of the relatively quiet red dwarf star Ross 128. The planet has mild temperatures that could allow for liquid water.\n   - **Distance from Earth:** About 11 light-years.\n\n9. **Teegarden's Star b**\n   - **Size:** Comparable to Earth.\n   - **Potential Habitability:** Orbits within the habitable zone of Teegarden's Star, a cool red dwarf. Conditions could be suitable for liquid water.\n   - **Distance from Earth:** Approximately 12 light-years.\n\n10. **Barnard's Star b**\n    - **Size:** A super-Earth with a mass of about 3.2 Earth masses.\n    - **Potential Habitability:** Located just outside the traditional habitable zone, but still within a range where liquid water could exist under certain conditions.\n    - **Distance from Earth:** About 6 light-years.\n\nThese discoveries highlight the diverse and intriguing nature of exoplanets found in the last decade. Each of these planets adds valuable information to our understanding of planetary formation, potential habitability, and the search for extraterrestrial life. Continued advancements in detection methods and technologies promise to further expand our knowledge in the years to come.\n</code></pre>"},{"location":"developers/test/","title":"Test","text":"<pre><code>python -m unittest tests.test \n</code></pre>"},{"location":"developers/wrapper-tools/","title":"Integrate with Tools","text":"<pre><code>from praisonai import PraisonAI\nfrom duckduckgo_search import DDGS\nfrom praisonai_tools import BaseTool\n\nclass InternetSearchTool(BaseTool):\n    name: str = \"InternetSearchTool\"\n    description: str = \"Search Internet for relevant information based on a query or latest news\"\n\n    def _run(self, query: str):\n        ddgs = DDGS()\n        results = ddgs.text(keywords=query, region='wt-wt', safesearch='moderate', max_results=5)\n        return results\n\n# Example agent_yaml content\nagent_yaml = \"\"\"\nframework: \"crewai\"\ntopic: \"Space Exploration\"\n\nroles:\n  astronomer:\n    role: \"Space Researcher\"\n    goal: \"Discover new insights about {topic}\"\n    backstory: \"You are a curious and dedicated astronomer with a passion for unraveling the mysteries of the cosmos.\"\n    tasks:\n      investigate_exoplanets:\n        description: \"Research and compile information about exoplanets discovered in the last decade.\"\n        expected_output: \"A summarized report on exoplanet discoveries, including their size, potential habitability, and distance from Earth.\"\n    tools:\n      - \"InternetSearchTool\"\n\"\"\"\n\n# Create a PraisonAI instance with the agent_yaml content\npraisonai = PraisonAI(agent_yaml=agent_yaml)\n\n# Run PraisonAI\nresult = praisonai.run()\n\n# Print the result\nprint(result)\n</code></pre>"},{"location":"developers/wrapper/","title":"Include praisonai package in your project","text":""},{"location":"developers/wrapper/#option-1-using-raw-yaml","title":"Option 1: Using RAW YAML","text":"<pre><code>from praisonai import PraisonAI\n\n# Example agent_yaml content\nagent_yaml = \"\"\"\nframework: \"crewai\"\ntopic: \"Space Exploration\"\n\nroles:\n  astronomer:\n    role: \"Space Researcher\"\n    goal: \"Discover new insights about {topic}\"\n    backstory: \"You are a curious and dedicated astronomer with a passion for unraveling the mysteries of the cosmos.\"\n    tasks:\n      investigate_exoplanets:\n        description: \"Research and compile information about exoplanets discovered in the last decade.\"\n        expected_output: \"A summarized report on exoplanet discoveries, including their size, potential habitability, and distance from Earth.\"\n\"\"\"\n\n# Create a PraisonAI instance with the agent_yaml content\npraisonai = PraisonAI(agent_yaml=agent_yaml)\n\n# Run PraisonAI\nresult = praisonai.run()\n\n# Print the result\nprint(result)\n</code></pre>"},{"location":"developers/wrapper/#option-2-using-separate-agentsyaml-file","title":"Option 2: Using separate agents.yaml file","text":"<p>Note: Please create agents.yaml file before hand. </p> <pre><code>from praisonai import PraisonAI\n\ndef basic(): # Basic Mode\n    praisonai = PraisonAI(agent_file=\"agents.yaml\")\n    praisonai.run()\n\nif __name__ == \"__main__\":\n    basic()\n</code></pre>"},{"location":"developers/wrapper/#other-options","title":"Other options","text":"<pre><code>from praisonai import PraisonAI\n\ndef basic(): # Basic Mode\n    praisonai = PraisonAI(agent_file=\"agents.yaml\")\n    praisonai.run()\n\ndef advanced(): # Advanced Mode with options\n    praisonai = PraisonAI(\n        agent_file=\"agents.yaml\",\n        framework=\"autogen\",\n    )\n    praisonai.run()\n\ndef auto(): # Full Automatic Mode\n    praisonai = PraisonAI(\n        auto=\"Create a movie script about car in mars\",\n        framework=\"autogen\"\n    )\n    print(praisonai.framework)\n    praisonai.run()\n\nif __name__ == \"__main__\":\n    basic()\n    advanced()\n    auto()\n</code></pre>"},{"location":"framework/autogen/","title":"AutoGen Low Code with Praison AI","text":"<p>Low Code solution to run AutoGen</p> <pre><code>pip install praisonai\n</code></pre> <pre><code>export OPENAI_API_KEY=xxxxxxxxxx\n</code></pre> <pre><code>praisonai --framework autogen --init Create a Movie Script About Cat in Mars\n</code></pre> <pre><code>praisonai --framework autogen\n</code></pre>"},{"location":"framework/crewai/","title":"CrewAI Low Code with PraisonAI","text":"<p>Low Code solution to run CrewAI</p> <pre><code>pip install praisonai\n</code></pre> <pre><code>export OPENAI_API_KEY=xxxxxxxxxx\n</code></pre> <pre><code>praisonai --framework crewai --init Create a Movie Script About Cat in Mars\n</code></pre> <pre><code>praisonai --framework crewai\n</code></pre>"},{"location":"models/anthropic/","title":"Add Anthropic to Praison AI","text":"<p><pre><code>pip install langchain-anthropic\n</code></pre> <pre><code>export ANTHROPIC_API_KEY=xxxxxxxxxx\n</code></pre></p>"},{"location":"models/anthropic/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"anthropic/claude-3-haiku-20240307\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/cohere/","title":"Add COHERE to Praison AI","text":"<p><pre><code>pip install langchain-cohere\n</code></pre> <pre><code>export COHERE_API_KEY=xxxxxxxxxx\n</code></pre></p>"},{"location":"models/cohere/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"cohere/command-r\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/google/","title":"Add Google Gemini to Praison AI","text":"<p><pre><code>pip install langchain-google-genai\n</code></pre> <pre><code>export GOOGLE_API_KEY=xxxxxxxxxx\n</code></pre></p>"},{"location":"models/google/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"google/gemini-1.5-flash-001\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/groq/","title":"Add GROQ to Praison AI","text":"<pre><code>export GROQ_API_KEY=xxxxxxxxxx\n</code></pre>"},{"location":"models/groq/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"groq/llama3-70b-8192\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/mistral/","title":"Add Mistral to Praison AI","text":"<p>Note: If you want to use Mistral via Ollama, please refer to Ollama document. This is for using Mistral from https://mistral.ai </p>"},{"location":"models/mistral/#using-single-agent","title":"Using Single Agent","text":"<pre><code>export OPENAI_API_KEY=xxxxxxxxxx\nexport OPENAI_MODEL_NAME=mistral-large\nexport OPENAI_API_BASE=\"https://api.mistral.ai/v1\"\n</code></pre>"},{"location":"models/mistral/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/ollama/","title":"Add Ollama to Praison AI","text":""},{"location":"models/ollama/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"ollama/llama3\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/openai/","title":"Add OPENAI ChatGPT to Praison AI","text":""},{"location":"models/openai/#using-single-agent","title":"Using Single Agent","text":"<pre><code>export OPENAI_API_KEY=xxxxxxxxxx\nexport OPENAI_MODEL_NAME=gpt-4o\n</code></pre>"},{"location":"models/openai/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre> <p>You can also mention the model name in the agents.yaml file</p>"},{"location":"models/openai/#agentsyaml-file_1","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"gpt-4o\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/openai/#using-multi-agents","title":"Using Multi Agents","text":"<p><pre><code>pip install langchain-openai\n</code></pre> <pre><code>export OPENAI_API_KEY=xxxxxxxxxx\n</code></pre></p>"},{"location":"models/openai/#agentsyaml-file_2","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"openai/gpt-4o\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/openrouter/","title":"Add OpenRouter to Praison AI","text":"<pre><code>export OPENROUTER_API_KEY=xxxxxxxxxx\n</code></pre>"},{"location":"models/openrouter/#agentsyaml-file","title":"agents.yaml file","text":"<pre><code>framework: crewai\ntopic: create movie script about cat in mars\nroles:\n  researcher:\n    backstory: Skilled in finding and organizing information, with a focus on research\n      efficiency.\n    goal: Gather information about Mars and cats\n    role: Researcher\n    llm:  \n      model: \"openrouter/anthropic/claude-3.5-sonnet\"\n    tasks:\n      gather_research:\n        description: Research and gather information about Mars, its environment,\n          and cats, including their behavior and characteristics.\n        expected_output: Document with research findings, including interesting facts\n          and information.\n    tools:\n    - ''\n</code></pre>"},{"location":"models/other/","title":"Other Models","text":"<pre><code># Ollama\nOPENAI_API_BASE='http://localhost:11434/v1'\nOPENAI_MODEL_NAME='mistral'\nOPENAI_API_KEY='NA'\n\n# FastChat\nOPENAI_API_BASE=\"http://localhost:8001/v1\"\nOPENAI_MODEL_NAME='oh-2.5m7b-q51'\nOPENAI_API_KEY=NA\n\n# LM Studio\nOPENAI_API_BASE=\"http://localhost:1234/v1\"\nOPENAI_MODEL_NAME=NA\nOPENAI_API_KEY=NA\n\n# Mistral API\nOPENAI_API_BASE=https://api.mistral.ai/v1\nOPENAI_MODEL_NAME=\"mistral-small\"\nOPENAI_API_KEY=your-mistral-api-key\n</code></pre>"},{"location":"monitoring/agentops/","title":"AgentOps PraisonAI Monitoring","text":"<pre><code>pip install \"praisonai[agentops]\"\n</code></pre> <pre><code>export AGENTOPS_API_KEY=xxxxxxxx\n</code></pre>"},{"location":"monitoring/agentops/#dashboard","title":"Dashboard","text":""},{"location":"tools/crawl4ai/","title":"Crawl4AI Praison AI Integration","text":""},{"location":"tools/crawl4ai/#install","title":"Install","text":"<pre><code>pip install \"crawl4ai @ git+https://github.com/unclecode/crawl4ai.git\" transformers torch nltk\n</code></pre> <pre><code>pip install praisonai\nexport OPENAI_API_KEY=xxxxxxxxx\n</code></pre>"},{"location":"tools/crawl4ai/#toolspy","title":"tools.py","text":"<pre><code>import os\nfrom crawl4ai import WebCrawler\nfrom crawl4ai.extraction_strategy import LLMExtractionStrategy\nfrom pydantic import BaseModel, Field\n\nclass OpenAIModelFee(BaseModel):\n    model_name: str = Field(..., description=\"Name of the OpenAI model.\")\n    input_fee: str = Field(..., description=\"Fee for input token for the OpenAI model.\")\n    output_fee: str = Field(..., description=\"Fee for output token \u00dffor the OpenAI model.\")\n\nurl = 'https://openai.com/api/pricing/'\ncrawler = WebCrawler()\ncrawler.warmup()\n\nresult = crawler.run(\n        url=url,\n        word_count_threshold=1,\n        extraction_strategy= LLMExtractionStrategy(\n            provider= \"openai/gpt-4o\", api_token = os.getenv('OPENAI_API_KEY'), \n            schema=OpenAIModelFee.schema(),\n            extraction_type=\"schema\",\n            instruction=\"\"\"From the crawled content, extract all mentioned model names along with their fees for input and output tokens. \n            Do not miss any models in the entire content. One extracted model JSON format should look like this: \n            {\"model_name\": \"GPT-4\", \"input_fee\": \"US$10.00 / 1M tokens\", \"output_fee\": \"US$30.00 / 1M tokens\"}.\"\"\"\n        ),            \n        bypass_cache=True,\n    )\n\nprint(result.extracted_content)\n</code></pre>"},{"location":"tools/crawl4ai/#agentsyaml","title":"agents.yaml","text":"<pre><code>framework: crewai\ntopic: extract model pricing from websites\nroles:\n  web_scraper:\n    backstory: An expert in web scraping with a deep understanding of extracting structured\n      data from online sources. https://openai.com/api/pricing/ https://www.anthropic.com/pricing https://cohere.com/pricing\n    goal: Gather model pricing data from various websites\n    role: Web Scraper\n    tasks:\n      scrape_model_pricing:\n        description: Scrape model pricing information from the provided list of websites.\n        expected_output: Raw HTML or JSON containing model pricing data.\n    tools:\n    - 'ModelFeeTool'\ndependencies: []\n</code></pre>"},{"location":"tools/crawl4ai/#run","title":"Run","text":"<pre><code>praisonai\n</code></pre>"},{"location":"tools/custom/","title":"Create Custom Tools","text":"<p>Sure! Let's go through the steps to install and set up the PraisonAI tool.</p> <p>Quickstart: Use PraisonAI Tools Creator GPT to get started quickly.</p>"},{"location":"tools/custom/#step-1-install-the-praisonai-package","title":"Step 1: Install the <code>praisonai</code> Package","text":"<p>First, you need to install the <code>praisonai</code> package. Open your terminal and run the following command:</p> <pre><code>pip install praisonai\n</code></pre>"},{"location":"tools/custom/#step-2-create-the-internetsearchtool","title":"Step 2: Create the <code>InternetSearchTool</code>","text":"<p>Next, create a file named <code>tools.py</code> and add the following code to define the <code>InternetSearchTool</code>:</p> <pre><code>from duckduckgo_search import DDGS\nfrom praisonai_tools import BaseTool\n\nclass InternetSearchTool(BaseTool):\n    name: str = \"Internet Search Tool\"\n    description: str = \"Search Internet for relevant information based on a query or latest news\"\n\n    def _run(self, query: str):\n        ddgs = DDGS()\n        results = ddgs.text(keywords=query, region='wt-wt', safesearch='moderate', max_results=5)\n        return results\n</code></pre>"},{"location":"tools/custom/#step-3-define-the-agent-configuration","title":"Step 3: Define the Agent Configuration","text":"<p>Create a file named <code>agents.yaml</code> and add the following content to configure the agent:</p> <pre><code>framework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - InternetSearchTool\n</code></pre>"},{"location":"tools/custom/#step-4-run-the-praisonai-tool","title":"Step 4: Run the PraisonAI Tool","text":"<p>To run the PraisonAI tool, simply type the following command in your terminal:</p> <pre><code>praisonai\n</code></pre> <p>If you want to run the <code>autogen</code> framework, use:</p> <pre><code>praisonai --framework autogen\n</code></pre>"},{"location":"tools/custom/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the <code>duckduckgo_search</code> package installed. If not, you can install it using:</p> <pre><code>pip install duckduckgo_search\n</code></pre> <p>That's it! You should now have the PraisonAI tool installed and configured.</p>"},{"location":"tools/custom/#other-information","title":"Other information","text":""},{"location":"tools/custom/#tldr-to-create-a-custom-tool","title":"TL;DR to Create a Custom Tool","text":"<pre><code>pip install praisonai duckduckgo-search\nexport OPENAI_API_KEY=\"Enter your API key\"\npraisonai --init research about the latest AI News and prepare a detailed report\n</code></pre> <ul> <li>Add <code>- InternetSearchTool</code> in the agents.yaml file in the tools section. </li> <li>Create a file called tools.py and add this code tools.py</li> </ul> <pre><code>praisonai\n</code></pre>"},{"location":"tools/custom/#pre-requisite-to-create-a-custom-tool","title":"Pre-requisite to Create a Custom Tool","text":"<p><code>agents.yaml</code> file should be present in the current directory. </p> <p>If it doesn't exist, create it by running the command <code>praisonai --init research about the latest AI News and prepare a detailed report</code>.</p>"},{"location":"tools/custom/#step-1-to-create-a-custom-tool","title":"Step 1 to Create a Custom Tool","text":"<p>Create a file called tools.py in the same directory as the agents.yaml file.</p> <pre><code># example tools.py\nfrom duckduckgo_search import DDGS\nfrom praisonai_tools import BaseTool\n\nclass InternetSearchTool(BaseTool):\n    name: str = \"InternetSearchTool\"\n    description: str = \"Search Internet for relevant information based on a query or latest news\"\n\n    def _run(self, query: str):\n        ddgs = DDGS()\n        results = ddgs.text(keywords=query, region='wt-wt', safesearch='moderate', max_results=5)\n        return results\n</code></pre>"},{"location":"tools/custom/#step-2-to-create-a-custom-tool","title":"Step 2 to Create a Custom Tool","text":"<p>Add the tool to the agents.yaml file as show below under the tools section <code>- InternetSearchTool</code>.</p> <pre><code>framework: crewai\ntopic: research about the latest AI News and prepare a detailed report\nroles:\n  research_analyst:\n    backstory: Experienced in gathering and analyzing data related to AI news trends.\n    goal: Analyze AI News trends\n    role: Research Analyst\n    tasks:\n      gather_data:\n        description: Conduct in-depth research on the latest AI News trends from reputable\n          sources.\n        expected_output: Comprehensive report on current AI News trends.\n    tools:\n    - InternetSearchTool\n</code></pre>"},{"location":"tools/duckduckgo/","title":"DuckDuckGo Praison AI Integration","text":"<pre><code>pip install duckduckgo_search\n</code></pre> <p>Create a file called tools.py in the same directory as the agents.yaml file.</p> <pre><code># example tools.py\nfrom duckduckgo_search import DDGS\nfrom praisonai_tools import BaseTool\n\nclass InternetSearchTool(BaseTool):\n    name: str = \"InternetSearchTool\"\n    description: str = \"Search Internet for relevant information based on a query or latest news\"\n\n    def _run(self, query: str):\n        ddgs = DDGS()\n        results = ddgs.text(keywords=query, region='wt-wt', safesearch='moderate', max_results=5)\n        return results\n</code></pre>"},{"location":"tools/gpt/","title":"PraisonAI Tools Creator GPT","text":"<p>Use PraisonAI Tools Creator GPT to get started quickly.</p>"},{"location":"tools/langchain/","title":"Langchain Tools","text":""},{"location":"tools/langchain/#integrate-langchain-direct-tools","title":"Integrate Langchain Direct Tools","text":"<pre><code>pip install youtube_search praisonai langchain_community langchain\n</code></pre> <pre><code># tools.py\nfrom langchain_community.tools import YouTubeSearchTool\n</code></pre> <pre><code># agents.yaml\nframework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung\n          diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - 'YouTubeSearchTool'\n</code></pre>"},{"location":"tools/langchain/#integrate-langchain-with-wrappers","title":"Integrate Langchain with Wrappers","text":"<pre><code>pip install wikipedia langchain_community\n</code></pre> <pre><code># tools.py\nfrom langchain_community.utilities import WikipediaAPIWrapper\nclass WikipediaSearchTool(BaseTool):\n    name: str = \"WikipediaSearchTool\"\n    description: str = \"Search Wikipedia for relevant information based on a query.\"\n\n    def _run(self, query: str):\n        api_wrapper = WikipediaAPIWrapper(top_k_results=4, doc_content_chars_max=100)\n        results = api_wrapper.load(query=query)\n        return results\n</code></pre> <pre><code># agents.yaml\nframework: crewai\ntopic: research about nvidia growth\nroles:\n  data_collector:\n    backstory: An experienced researcher with the ability to efficiently collect and\n      organize vast amounts of data.\n    goal: Gather information on Nvidia's growth by providing the Ticket Symbol to YahooFinanceNewsTool\n    role: Data Collector\n    tasks:\n      data_collection_task:\n        description: Collect data on Nvidia's growth from various sources such as\n          financial reports, news articles, and company announcements.\n        expected_output: A comprehensive document detailing data points on Nvidia's\n          growth over the years.\n    tools:\n    - 'WikipediaSearchTool'\n</code></pre>"},{"location":"tools/reddit/","title":"Reddit PraisonAI Integration","text":"<pre><code>export REDDIT_USER_AGENT=[USER]\nexport REDDIT_CLIENT_SECRET=xxxxxx\nexport REDDIT_CLIENT_ID=xxxxxx\n</code></pre> <p>tools.py</p> <pre><code>from langchain_community.tools.reddit_search.tool import RedditSearchRun\n</code></pre> <p>agents.yaml</p> <pre><code>framework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung\n          diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - 'RedditSearchRun'\n</code></pre>"},{"location":"tools/tavily/","title":"Tavily PraisonAI Integration","text":"<pre><code>from praisonai_tools import BaseTool\nfrom langchain.utilities.tavily_search import TavilySearchAPIWrapper\n\nclass TavilyTool(BaseTool):\n    name: str = \"TavilyTool\"\n    description: str = \"Search Tavily for relevant information based on a query.\"\n\n    def _run(self, query: str):\n        api_wrapper = TavilySearchAPIWrapper()\n        results = api_wrapper.results(query=query, max_results=5)\n        return results\n</code></pre>"},{"location":"tools/wikipedia/","title":"Wikipedia PraisonAI Integration","text":"<pre><code>pip install wikipedia langchain_community\n</code></pre> <pre><code># tools.py\nfrom langchain_community.utilities import WikipediaAPIWrapper\nclass WikipediaSearchTool(BaseTool):\n    name: str = \"WikipediaSearchTool\"\n    description: str = \"Search Wikipedia for relevant information based on a query.\"\n\n    def _run(self, query: str):\n        api_wrapper = WikipediaAPIWrapper(top_k_results=4, doc_content_chars_max=100)\n        results = api_wrapper.load(query=query)\n        return results\n</code></pre> <pre><code># agents.yaml\nframework: crewai\ntopic: research about nvidia growth\nroles:\n  data_collector:\n    backstory: An experienced researcher with the ability to efficiently collect and\n      organize vast amounts of data.\n    goal: Gather information on Nvidia's growth by providing the Ticket Symbol to YahooFinanceNewsTool\n    role: Data Collector\n    tasks:\n      data_collection_task:\n        description: Collect data on Nvidia's growth from various sources such as\n          financial reports, news articles, and company announcements.\n        expected_output: A comprehensive document detailing data points on Nvidia's\n          growth over the years.\n    tools:\n    - 'WikipediaSearchTool'\n</code></pre>"},{"location":"tools/you.com/","title":"You.com PraisonAI Integration","text":"<p><pre><code>export YDC_API_KEY=xxxxxxxxxxxx\n</code></pre> tools.py <pre><code>from langchain_community.utilities.you import YouSearchAPIWrapper\nclass YouSearchTool(BaseTool):\n    name: str = \"You Search Tool\"\n    description: str = \"Search You.com for relevant information based on a query.\"\n\n    def _run(self, query: str):\n        api_wrapper = YouSearchAPIWrapper()\n        results = api_wrapper.results(query=query, max_results=5)\n        return results\n</code></pre></p> <p>agents.yaml</p> <pre><code>framework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung\n          diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - 'YouSearchTool'\n</code></pre>"},{"location":"tools/youtube/","title":"YouTube Search PraisonAI Integration","text":"<pre><code>pip install youtube_search praisonai langchain_community langchain\n</code></pre> <pre><code># tools.py\nfrom langchain_community.tools import YouTubeSearchTool\n</code></pre> <pre><code># agents.yaml\nframework: crewai\ntopic: research about the causes of lung disease\nroles:\n  research_analyst:\n    backstory: Experienced in analyzing scientific data related to respiratory health.\n    goal: Analyze data on lung diseases\n    role: Research Analyst\n    tasks:\n      data_analysis:\n        description: Gather and analyze data on the causes and risk factors of lung\n          diseases.\n        expected_output: Report detailing key findings on lung disease causes.\n    tools:\n    - 'YouTubeSearchTool'\n</code></pre>"},{"location":"ui/chat/","title":"PraisonAI Chat","text":"<p>Use 100+ LLMs</p> <ol> <li> <pre><code>pip install \"praisonai[chat]\"\n</code></pre> </li> <li> <pre><code>export OPENAI_API_KEY=xxxxxxxx\n</code></pre> </li> <li> <pre><code>praisonai chat\n</code></pre> </li> <li> <p>Set Model name to be gpt-3.5-turbo in the settings </p> </li> </ol>"},{"location":"ui/code/","title":"PraisonAI Code","text":"<p>PraisonAI Code helps you to interact with your whole codebase using the power of AI.</p> <ol> <li> <pre><code>pip install \"praisonai[code]\"\n</code></pre> </li> <li> <pre><code>export OPENAI_API_KEY=xxxxxxxx\n</code></pre> </li> <li> <pre><code>praisonai code\n</code></pre> </li> <li> <p>Username and Password will be asked for the first time. <code>admin</code> is the default username and password.</p> </li> <li> <p>Set Model name to be gpt-3.5-turbo in the settings </p> </li> </ol>"},{"location":"ui/code/#other-models","title":"Other Models","text":"<ul> <li>Use 100+ LLMs</li> <li>Includes Gemini 1.5 for 2 Million Context Length</li> </ul>"},{"location":"ui/code/#to-use-gemini-15","title":"To Use Gemini 1.5","text":"<ul> <li><code>export GEMINI_API_KEY=xxxxxxxxx</code></li> <li><code>praisonai code</code></li> <li>Set Model name to be <code>gemini/gemini-1.5-flash</code> in the settings</li> </ul>"},{"location":"ui/code/#ignore-files","title":"Ignore Files","text":""},{"location":"ui/code/#using-settingsyaml","title":"Using settings.yaml","text":"<ul> <li>Create a settings.yaml file in the root folder of the project</li> <li>Add below Variables and required Ignore Files</li> </ul> <pre><code>code:\n  ignore_files:\n  - \".*\"\n  - \"*.pyc\"\n  - \"pycache\"\n  - \".git\"\n  - \".gitignore\"\n  - \".vscode\"\n  - \".idea\"\n  - \".DS_Store\"\n  - \".lock\"\n  - \".pyc\"\n  - \".env\"\n</code></pre>"},{"location":"ui/code/#using-env-file","title":"Using .env File","text":"<ul> <li>Create a .env file in the root folder of the project</li> <li>Add below Variables and required Ignore Files</li> </ul> <pre><code>PRAISONAI_IGNORE_FILES=\".*,*.pyc,__pycache__,.git,.gitignore,.vscode,.idea,.DS_Store,*.lock,.env,docs,tests,test,tmp,temp,*.txt,*.md,*.json,*.csv,*.tsv,public,*.sql,*.sqlite,*.db,*.db3,*.sqlite3,*.log,*.zip,*.gz,*.tar,*.rar,*.7z,*.pdf,*.jpg,*.jpeg,*.png,*.gif,*.svg,cookbooks,assets,dist,build,node_modules,venv,crewAI,.cache,*.__pycache__,*chroma.sqlite3,test/,dist/,praisonAI.egg-info,test.yaml,db,praisonai_prompt.txt,watch.sh,docs.sh,other,output,*.chainlit,.files,site,flagged,*public,threads.db,trained_agents_data.pkl,.pytest_cache\"\n</code></pre>"},{"location":"ui/code/#using-environment-variables-in-the-terminal","title":"Using Environment Variables in the Terminal","text":"<pre><code>export PRAISONAI_IGNORE_FILES=\".*,*.pyc,__pycache__,.git,.gitignore,.vscode,.idea,.DS_Store,*.lock,.env,docs,tests,test,tmp,temp,*.txt,*.md,*.json,*.csv,*.tsv,public,*.sql,*.sqlite,*.db,*.db3,*.sqlite3,*.log,*.zip,*.gz,*.tar,*.rar,*.7z,*.pdf,*.jpg,*.jpeg,*.png,*.gif,*.svg,cookbooks,assets,dist,build,node_modules,venv,crewAI,.cache,*.__pycache__,*chroma.sqlite3,test/,dist/,praisonAI.egg-info,test.yaml,db,praisonai_prompt.txt,watch.sh,docs.sh,other,output,*.chainlit,.files,site,flagged,*public,threads.db,trained_agents_data.pkl,.pytest_cache\"\n</code></pre>"},{"location":"ui/code/#set-max-tokens","title":"Set Max Tokens","text":"<p>Note: By Default Max Tokens set is 128,000</p> <pre><code>export PRAISONAI_MAX_TOKENS=200000\n</code></pre> <p>or </p> <ul> <li>Create a .env file in the root folder of the project</li> <li>Add below Variables and required Max Tokens</li> <li><code>PRAISONAI_MAX_TOKENS=200000</code></li> </ul>"},{"location":"ui/ui/","title":"PraisonAI User Interface (UI)","text":""},{"location":"ui/ui/#different-user-interfaces","title":"Different User Interfaces:","text":"Interface Description URL UI Multi Agents such as CrewAI or AutoGen https://docs.praison.ai/ui/ui Chat Chat with 100+ LLMs, single AI Agent https://docs.praison.ai/ui/chat Code Chat with entire Codebase, single AI Agent https://docs.praison.ai/ui/code"},{"location":"ui/ui/#chainlit","title":"Chainlit","text":"<pre><code>pip install -U \"praisonai[ui]\"\nexport OPENAI_API_KEY=\"Enter your API key\"\nchainlit create-secret\nexport CHAINLIT_AUTH_SECRET=xxxxxxxx\npraisonai ui\n</code></pre> <p>or </p> <pre><code>python -m praisonai ui\n</code></pre> <p>Default Username: admin Default Password: admin</p>"},{"location":"ui/ui/#to-change-username-and-password","title":"To Change Username and Password","text":"<p>create .env file in the root folder of the project Add below Variables and required Username/Password <pre><code>CHAINLIT_USERNAME=admin\nCHAINLIT_USERNAME=admin\n</code></pre></p>"},{"location":"ui/ui/#gradio","title":"Gradio","text":"<pre><code>pip install \"praisonai[gradio]\"\nexport OPENAI_API_KEY=\"Enter your API key\"\npraisonai --ui gradio\n</code></pre>"},{"location":"ui/ui/#streamlit","title":"Streamlit","text":"<pre><code>git clone https://github.com/leporejoseph/PraisonAi-Streamlit\ncd PraisonAi-Streamlit\npip install -r requirements.txt\nstreamlit run app.py\n</code></pre>"},{"location":"ui/ui/#using-chainlit-with-pictures","title":"Using Chainlit (with Pictures)","text":""},{"location":"ui/ui/#run-automatically","title":"Run Automatically","text":""},{"location":"ui/ui/#install-required-package","title":"Install Required Package","text":""},{"location":"ui/ui/#user-interface","title":"User Interface","text":""},{"location":"ui/ui/#select-auto-mode","title":"Select Auto Mode","text":""},{"location":"ui/ui/#configure-agent-settings","title":"Configure Agent Settings","text":""},{"location":"ui/ui/#define-a-task-to-auto-generate-agents-and-run","title":"Define a Task to Auto Generate Agents and Run","text":""},{"location":"ui/ui/#output","title":"Output","text":""},{"location":"ui/ui/#run-manually","title":"Run Manually","text":""},{"location":"ui/ui/#select-manual-mode","title":"Select Manual Mode","text":""},{"location":"ui/ui/#modify-agents-and-tools","title":"Modify Agents and Tools","text":""},{"location":"ui/ui/#review-generated-agents","title":"Review Generated Agents","text":""},{"location":"ui/ui/#run-agents","title":"Run Agents","text":""},{"location":"ui/ui/#manual-model-output","title":"Manual Model Output","text":""}]}