{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc1b7810",
      "metadata": {
        "id": "cc1b7810"
      },
      "source": [
        "# Phi-4 (14B) Conversational with GRPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c882a2d",
      "metadata": {
        "id": "9c882a2d"
      },
      "source": [
        "**Description:**\n",
        "\n",
        "This notebook demonstrates inference using the Phi-4 14B parameter model with GRPO optimization strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DhivyaBharathy-web/PraisonAI/blob/main/examples/cookbooks/Phi_4_14B_GRPO.ipynb)\n"
      ],
      "metadata": {
        "id": "Z7azojscP0Ax"
      },
      "id": "Z7azojscP0Ax"
    },
    {
      "cell_type": "markdown",
      "id": "e8616784",
      "metadata": {
        "id": "e8616784"
      },
      "source": [
        "**Dependencies**\n",
        "\n",
        "```python\n",
        "!pip install transformers accelerate\n",
        "!pip install torch\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09866448",
      "metadata": {
        "id": "09866448"
      },
      "source": [
        "**Tools Used**\n",
        "\n",
        "- HuggingFace Transformers\n",
        "- GRPO Optimization\n",
        "- PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403b0c37",
      "metadata": {
        "id": "403b0c37"
      },
      "source": [
        "**YAML Prompt**\n",
        "\n",
        "```yaml\n",
        "system: Act as a professional consultant.\n",
        "user: How can AI help in healthcare?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1785bcd",
      "metadata": {
        "id": "e1785bcd"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-4-14b\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-4-14b\")\n",
        "\n",
        "prompt = \"How can AI help in healthcare?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=60)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074e4e6e",
      "metadata": {
        "id": "074e4e6e"
      },
      "source": [
        "**Output**\n",
        "\n",
        "The model generates thoughtful insights on AI applications in healthcare.\n",
        "\n",
        "How can AI help in healthcare?\n",
        "\n",
        "AI can assist in healthcare by improving diagnostics, predicting patient outcomes, personalizing treatments, and enhancing administrative workflows. It enables faster data analysis and decision-making, leading to better patient care.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}